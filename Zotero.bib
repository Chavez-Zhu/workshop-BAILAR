
@inproceedings{kocsis_bandit-based_2006,
	title = {Bandit-{Based} {Monte}-{Carlo} planning},
	url = {http://link.springer.com/chapter/10.1007/11871842_29},
	booktitle = {European conference on machine learning},
	publisher = {Springer},
	author = {Kocsis, Levente and Szepesvari, Csaba},
	year = {2006},
	pages = {282--293}
}

@article{woodward_framing_2012,
	title = {Framing {Human}-{Robot} {Task} {Communication} as a {Partially} {Observable} {Markov} {Decision} {Process}},
	copyright = {open},
	url = {https://dash.harvard.edu/handle/1/9396429},
	abstract = {As general purpose robots become more capable, pre-programming of all tasks at the factory will become less practical. We would like for non-technical human owners to be able to communicate, through interaction with their robot, the details of a new task; I call this interaction "task communication". During task communication the robot must infer the details of the task from unstructured human signals, and it must choose actions that facilitate this inference. In this dissertation I propose the use of a partially observable Markov decision process (POMDP) for representing the task communication problem; with the unobservable task details and unobservable intentions of the human teacher captured in the state, with all signals from the human represented as observations, and with the cost function chosen to penalize uncertainty. This dissertation presents the framework, works through an example of framing task communication as a POMDP, and presents results from a user experiment where subjects communicated a task to a POMDP-controlled virtual robot and to a human controlled virtual robot. The task communicated in the experiment consisted of a single object movement and the communication in the experiment was limited to binary approval signals from the teacher. This dissertation makes three contributions: 1) It frames human-robot task communication as a POMDP, a widely used framework. This enables the leveraging of techniques developed for other problems framed as a POMDP. 2) It provides an example of framing a task communication problem as a POMDP. 3) It validates the framework through results from a user experiment. The results suggest that the proposed POMDP framework produces robots that are robust to teacher error, that can accurately infer task details, and that are perceived to be intelligent.},
	language = {en\_US},
	urldate = {2017-06-13TZ},
	author = {Woodward, Mark P.},
	month = aug,
	year = {2012}
}

@incollection{kulkarni_hierarchical_2016,
	title = {Hierarchical {Deep} {Reinforcement} {Learning}: {Integrating} {Temporal} {Abstraction} and {Intrinsic} {Motivation}},
	shorttitle = {Hierarchical {Deep} {Reinforcement} {Learning}},
	url = {http://papers.nips.cc/paper/6233-hierarchical-deep-reinforcement-learning-integrating-temporal-abstraction-and-intrinsic-motivation.pdf},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 29},
	publisher = {Curran Associates, Inc.},
	author = {Kulkarni, Tejas D and Narasimhan, Karthik and Saeedi, Ardavan and Tenenbaum, Josh},
	editor = {Lee, D. D. and Sugiyama, M. and Luxburg, U. V. and Guyon, I. and Garnett, R.},
	year = {2016},
	pages = {3675--3683}
}

@inproceedings{chu_learning_2016,
	address = {Piscataway, NJ, USA},
	series = {{HRI} '16},
	title = {Learning {Object} {Affordances} by {Leveraging} the {Combination} of {Human}-{Guidance} and {Self}-{Exploration}},
	isbn = {978-1-4673-8370-7},
	url = {http://dl.acm.org/citation.cfm?id=2906831.2906869},
	abstract = {Our work focuses on robots to be deployed in human environments. These robots, which will need specialized object manipulation skills, should leverage end-users to efficiently learn the affordances of objects in their environment. This approach is promising because people naturally focus on showing salient aspects of the objects. We replicate prior results and build on them to create a combination of self and supervised learning. We present experimental results with a robot learning 5 affordances on 4 objects using 1219 interactions. We compare three conditions: (1) learning through self-exploration, (2) learning from supervised examples provided by 10 naive users, and (3) self-exploration biased by the user input. Our results characterize the benefits of self and supervised affordance learning and show that a combined approach is the most efficient and successful.},
	booktitle = {The {Eleventh} {ACM}/{IEEE} {International} {Conference} on {Human} {Robot} {Interaction}},
	publisher = {IEEE Press},
	author = {Chu, Vivian and Fitzgerald, Tesca and Thomaz, Andrea L.},
	year = {2016},
	pages = {221--228}
}

@inproceedings{oudeyer_playground_2005,
	title = {The playground experiment: {Task}-independent development of a curious robot},
	shorttitle = {The playground experiment},
	url = {http://www.verenahafner.de/papers/oudeyeretal.pdf},
	booktitle = {Proceedings of the {AAAI} {Spring} {Symposium} on {Developmental} {Robotics}},
	publisher = {Stanford, California},
	author = {Oudeyer, Pierre-Yves and Kaplan, Frederic and Hafner, Verena V. and Whyte, Andrew},
	year = {2005},
	pages = {42--47}
}

@inproceedings{lopes_simultaneous_2011,
	title = {Simultaneous acquisition of task and feedback models},
	volume = {2},
	doi = {10.1109/DEVLRN.2011.6037359},
	abstract = {We present a system to learn task representations from ambiguous feedback. We consider an inverse reinforcement learner that receives feedback from a teacher with an unknown and noisy protocol. The system needs to estimate simultaneously what the task is (i.e. how to find a compact representation to the task goal), and how the teacher is providing the feedback. We further explore the problem of ambiguous protocols by considering that the words used by the teacher have an unknown relation with the action and meaning expected by the robot. This allows the system to start with a set of known signs and learn the meaning of new ones. We present computational results that show that it is possible to learn the task under a noisy and ambiguous feedback. Using an active learning approach, the system is able to reduce the length of the training period.},
	booktitle = {2011 {IEEE} {International} {Conference} on {Development} and {Learning} ({ICDL})},
	author = {Lopes, M. and Cederborg, T. and Oudeyer, P. Y.},
	month = aug,
	year = {2011},
	pages = {1--7}
}

@inproceedings{fails_interactive_2003,
	address = {New York, NY, USA},
	series = {{IUI} '03},
	title = {Interactive {Machine} {Learning}},
	isbn = {978-1-58113-586-2},
	url = {http://doi.acm.org/10.1145/604045.604056},
	doi = {10.1145/604045.604056},
	abstract = {Perceptual user interfaces (PUIs) are an important part of ubiquitous computing. Creating such interfaces is difficult because of the image and signal processing knowledge required for creating classifiers. We propose an interactive machine-learning (IML) model that allows users to train, classify/view and correct the classifications. The concept and implementation details of IML are discussed and contrasted with classical machine learning models. Evaluations of two algorithms are also presented. We also briefly describe Image Processing with Crayons (Crayons), which is a tool for creating new camera-based interfaces using a simple painting metaphor. The Crayons tool embodies our notions of interactive machine learning},
	booktitle = {Proceedings of the 8th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {ACM},
	author = {Fails, Jerry Alan and Olsen, Jr., Dan R.},
	year = {2003},
	pages = {39--45}
}

@inproceedings{cakmak_designing_2012,
	address = {New York, NY, USA},
	series = {{HRI} '12},
	title = {Designing {Robot} {Learners} {That} {Ask} {Good} {Questions}},
	isbn = {978-1-4503-1063-5},
	url = {http://doi.acm.org/10.1145/2157689.2157693},
	doi = {10.1145/2157689.2157693},
	abstract = {Programming new skills on a robot should take minimal time and effort. One approach to achieve this goal is to allow the robot to ask questions. This idea, called Active Learning, has recently caught a lot of attention in the robotics community. However, it has not been explored from a human-robot interaction perspective. In this paper, we identify three types of questions (label, demonstration and feature queries) and discuss how a robot can use these while learning new skills. Then, we present an experiment on human question asking which characterizes the extent to which humans use these question types. Finally, we evaluate the three question types within a human-robot teaching interaction. We investigate the ease with which different types of questions are answered and whether or not there is a general preference of one type of question over another. Based on our findings from both experiments we provide guidelines for designing question asking behaviors on a robot learner.},
	booktitle = {Proceedings of the {Seventh} {Annual} {ACM}/{IEEE} {International} {Conference} on {Human}-{Robot} {Interaction}},
	publisher = {ACM},
	author = {Cakmak, Maya and Thomaz, Andrea L.},
	year = {2012},
	pages = {17--24}
}

@article{carlson_computational_2004,
	title = {A computational model of the emergence of gaze following},
	volume = {15},
	url = {http://www.academia.edu/download/42427371/CarlsonTriesch-NCPW2003.pdf},
	journal = {Progress in Neural Processing},
	author = {Carlson, Eric and Triesch, Jochen},
	year = {2004},
	pages = {105--114}
}

@inproceedings{breazeal_teaching_2004,
	title = {Teaching and working with robots as a collaboration},
	url = {http://dl.acm.org/citation.cfm?id=1018871},
	booktitle = {Proceedings of the {Third} {International} {Joint} {Conference} on {Autonomous} {Agents} and {Multiagent} {Systems}-{Volume} 3},
	publisher = {IEEE Computer Society},
	author = {Breazeal, Cynthia and Hoffman, Guy and Lockerd, Andrea},
	year = {2004},
	pages = {1030--1037}
}

@article{breazeal_robots_2002,
	title = {Robots that imitate humans},
	volume = {6},
	url = {http://www.sciencedirect.com/science/article/pii/S1364661302020168},
	number = {11},
	journal = {Trends in cognitive sciences},
	author = {Breazeal, Cynthia and Scassellati, Brian},
	year = {2002},
	pages = {481--487}
}

@inproceedings{nagai_role_2005,
	title = {The role of motion information in learning human-robot joint attention},
	url = {http://ieeexplore.ieee.org/abstract/document/1570418/},
	booktitle = {Robotics and {Automation}, 2005. {ICRA} 2005. {Proceedings} of the 2005 {IEEE} {International} {Conference} on},
	publisher = {IEEE},
	author = {Nagai, Yukie},
	year = {2005},
	pages = {2069--2074}
}

@article{nagai_learning_2006,
	title = {Learning for joint attention helped by functional development},
	volume = {20},
	url = {http://www.tandfonline.com/doi/abs/10.1163/156855306778522497},
	number = {10},
	journal = {Advanced Robotics},
	author = {Nagai, Yukie and Asada, Minoru and Hosoda, Koh},
	year = {2006},
	pages = {1165--1181}
}

@incollection{wertsch_creation_1984,
	address = {Cambridge, MA, US},
	title = {The creation of context in joint problem-solving},
	copyright = {(c) 2016 APA, all rights reserved},
	isbn = {978-0-674-27030-5 978-0-674-27031-2},
	abstract = {individual versus social phenomena the social perspective application of the Vygotskian approach methodology},
	booktitle = {Everyday cognition: {Its} development in social context},
	publisher = {Harvard University Press},
	author = {Wertsch, James V. and Minick, Norris and Arns, Flavio J.},
	editor = {Rogoff, B. and Lave, J.},
	year = {1984},
	pages = {151--171}
}

@inproceedings{hester_intrinsically_2012,
	title = {Intrinsically motivated model learning for a developing curious agent},
	url = {http://ieeexplore.ieee.org/abstract/document/6400802/},
	booktitle = {Development and {Learning} and {Epigenetic} {Robotics} ({ICDL}), 2012 {IEEE} {International} {Conference} on},
	publisher = {IEEE},
	author = {Hester, Todd and Stone, Peter},
	year = {2012},
	pages = {1--6}
}

@article{wertsch_creation_1984-1,
	title = {The creation of context in joint problem-solving.},
	url = {http://psycnet.apa.org/psycinfo/1988-98320-007},
	author = {Wertsch, James V. and Minick, Norris and Arns, Flavio J.},
	year = {1984}
}

@inproceedings{schillingmann_towards_2009,
	title = {Towards a computational model of acoustic packaging},
	url = {http://ieeexplore.ieee.org/abstract/document/5175523/},
	booktitle = {Development and {Learning}, 2009. {ICDL} 2009. {IEEE} 8th {International} {Conference} on},
	publisher = {IEEE},
	author = {Schillingmann, Lars and Wrede, Britta and Rohlfing, Katharina},
	year = {2009},
	pages = {1--6}
}

@article{adamson_still_2003,
	title = {The still face: {A} history of a shared experimental paradigm},
	volume = {4},
	shorttitle = {The still face},
	url = {http://www.tandfonline.com/doi/abs/10.1207/S15327078IN0404_01},
	number = {4},
	journal = {Infancy},
	author = {Adamson, Lauren B. and Frick, Janet E.},
	year = {2003},
	pages = {451--473}
}

@inproceedings{thomaz_real-time_2005,
	title = {Real-time interactive reinforcement learning for robots},
	url = {https://vvvvw.aaai.org/Papers/Workshops/2005/WS-05-04/WS05-04-002.pdf},
	booktitle = {{AAAI} 2005 workshop on human comprehensible machine learning},
	author = {Thomaz, Andrea Lockerd and Hoffman, Guy and Breazeal, Cynthia},
	year = {2005}
}

@inproceedings{thomaz_reinforcement_2006,
	title = {Reinforcement learning with human teachers: {Understanding} how people want to teach robots},
	shorttitle = {Reinforcement learning with human teachers},
	url = {http://ieeexplore.ieee.org/abstract/document/4107833/},
	booktitle = {Robot and {Human} {Interactive} {Communication}, 2006. {ROMAN} 2006. {The} 15th {IEEE} {International} {Symposium} on},
	publisher = {IEEE},
	author = {Thomaz, Andrea L. and Hoffman, Guy and Breazeal, Cynthia},
	year = {2006},
	pages = {352--357}
}

@article{little_learning_2013,
	title = {Learning and exploration in action-perception loops},
	volume = {7},
	issn = {1662-5110},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3619626/},
	doi = {10.3389/fncir.2013.00037},
	abstract = {Discovering the structure underlying observed data is a recurring problem in machine learning with important applications in neuroscience. It is also a primary function of the brain. When data can be actively collected in the context of a closed action-perception loop, behavior becomes a critical determinant of learning efficiency. Psychologists studying exploration and curiosity in humans and animals have long argued that learning itself is a primary motivator of behavior. However, the theoretical basis of learning-driven behavior is not well understood. Previous computational studies of behavior have largely focused on the control problem of maximizing acquisition of rewards and have treated learning the structure of data as a secondary objective. Here, we study exploration in the absence of external reward feedback. Instead, we take the quality of an agent's learned internal model to be the primary objective. In a simple probabilistic framework, we derive a Bayesian estimate for the amount of information about the environment an agent can expect to receive by taking an action, a measure we term the predicted information gain (PIG). We develop exploration strategies that approximately maximize PIG. One strategy based on value-iteration consistently learns faster than previously developed reward-free exploration strategies across a diverse range of environments. Psychologists believe the evolutionary advantage of learning-driven exploration lies in the generalized utility of an accurate internal model. Consistent with this hypothesis, we demonstrate that agents which learn more efficiently during exploration are later better able to accomplish a range of goal-directed tasks. We will conclude by discussing how our work elucidates the explorative behaviors of animals and humans, its relationship to other computational models of behavior, and its potential application to experimental design, such as in closed-loop neurophysiology studies.},
	journal = {Frontiers in Neural Circuits},
	author = {Little, Daniel Y. and Sommer, Friedrich T.},
	month = mar,
	year = {2013},
	pmid = {23579347},
	pmcid = {PMC3619626}
}

@inproceedings{dewey_reinforcement_2014,
	title = {Reinforcement learning and the reward engineering principle},
	url = {http://www.danieldewey.net/reward-engineering-principle.pdf},
	booktitle = {2014 {AAAI} {Spring} {Symposium} {Series}},
	author = {Dewey, Daniel},
	year = {2014}
}

@article{vollmer_pragmatic_2016,
	title = {Pragmatic frames for teaching and learning in human–robot interaction: {Review} and challenges},
	volume = {10},
	shorttitle = {Pragmatic frames for teaching and learning in human–robot interaction},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5046941/},
	journal = {Frontiers in neurorobotics},
	author = {Vollmer, Anna-Lisa and Wrede, Britta and Rohlfing, Katharina J. and Oudeyer, Pierre-Yves},
	year = {2016}
}

@article{guckelsberger_addressing_nodate,
	title = {Addressing the “{Why}?” in {Computational} {Creativity}: {A} {Non}-{Anthropocentric}, {Minimal} {Model} of {Intentional} {Creative} {Agency}},
	shorttitle = {Addressing the “{Why}?},
	url = {http://ccg.doc.gold.ac.uk/wp-content/uploads/2017/05/iccc2017_guckelsberger.pdf},
	author = {Guckelsberger, Christian and Salge, Christoph and Colton, Simon}
}

@article{edwards_cross-domain_2017,
	title = {Cross-{Domain} {Perceptual} {Reward} {Functions}},
	url = {http://arxiv.org/abs/1705.09045},
	abstract = {In reinforcement learning, we often define goals by specifying rewards within desirable states. One problem with this approach is that we typically need to redefine the rewards each time the goal changes, which often requires some understanding of the solution in the agents environment. When humans are learning to complete tasks, we regularly utilize alternative sources that guide our understanding of the problem. Such task representations allow one to specify goals on their own terms, thus providing specifications that can be appropriately interpreted across various environments. This motivates our own work, in which we represent goals in environments that are different from the agents. We introduce Cross-Domain Perceptual Reward (CDPR) functions, learned rewards that represent the visual similarity between an agents state and a cross-domain goal image. We report results for learning the CDPRs with a deep neural network and using them to solve two tasks with deep reinforcement learning.},
	journal = {arXiv:1705.09045 [cs]},
	author = {Edwards, Ashley D. and Isbell Jr, Charles L.},
	month = may,
	year = {2017},
	note = {arXiv: 1705.09045}
}

@phdthesis{vahala_one-shot_2017,
	title = {{ONE}-{SHOT}, {UNSUPERVISED} {LEARNING} {FOR} {IMPROVED} {HUMAN}-{ROBOT} {COLLABORATION}},
	url = {https://minds.wisconsin.edu/bitstream/handle/1793/76481/thesis_vahala_final.pdf?sequence=1},
	urldate = {2017-05-22TZ},
	school = {UNIVERSITY OF WISCONSIN-MADISON},
	author = {Vahala, Joshua S.},
	year = {2017}
}

@article{munzer_preference_nodate,
	title = {Preference {Learning} on the {Execution} of {Collaborative} {Human}-{Robot} {Tasks}},
	url = {http://web.tecnico.ulisboa.pt/manuel.lopes/myrefs/17-ICRA-preferences.pdf},
	urldate = {2017-05-22TZ},
	author = {Munzer, Thibaut and Toussaint, Marc and Lopes, Manuel}
}

@article{dubey_rational_2017,
	title = {A rational analysis of curiosity},
	url = {http://arxiv.org/abs/1705.04351},
	abstract = {We present a rational analysis of curiosity, proposing that people's curiosity is driven by seeking stimuli that maximize their ability to make appropriate responses in the future. This perspective offers a way to unify previous theories of curiosity into a single framework. Experimental results confirm our model's predictions, showing how the relationship between curiosity and confidence can change significantly depending on the nature of the environment.},
	urldate = {2017-05-22TZ},
	journal = {arXiv:1705.04351 [cs]},
	author = {Dubey, Rachit and Griffiths, Thomas L.},
	month = may,
	year = {2017},
	note = {arXiv: 1705.04351}
}

@article{moerland_emotion_2017,
	title = {Emotion in {Reinforcement} {Learning} {Agents} and {Robots}: {A} {Survey}},
	shorttitle = {Emotion in {Reinforcement} {Learning} {Agents} and {Robots}},
	url = {http://arxiv.org/abs/1705.05172},
	abstract = {This article provides the first survey of computational models of emotion in reinforcement learning (RL) agents. The survey focuses on agent/robot emotions, and mostly ignores human user emotions. Emotions are recognized as functional in decision-making by influencing motivation and action selection. Therefore, computational emotion models are usually grounded in the agent's decision making architecture, of which RL is an important subclass. Studying emotions in RL-based agents is useful for three research fields. For machine learning (ML) researchers, emotion models may improve learning efficiency. For the interactive ML and human-robot interaction (HRI) community, emotions can communicate state and enhance user investment. Lastly, it allows affective modelling (AM) researchers to investigate their emotion theories in a successful AI agent class. This survey provides background on emotion theory and RL. It systematically addresses 1) from what underlying dimensions (e.g., homeostasis, appraisal) emotions can be derived and how these can be modelled in RL-agents, 2) what types of emotions have been derived from these dimensions, and 3) how these emotions may either influence the learning efficiency of the agent or be useful as social signals. We also systematically compare evaluation criteria, and draw connections to important RL sub-domains like (intrinsic) motivation and model-based RL. In short, this survey provides both a practical overview for engineers wanting to implement emotions in their RL agents, and identifies challenges and directions for future emotion-RL research.},
	urldate = {2017-05-22TZ},
	journal = {arXiv:1705.05172 [cs, stat]},
	author = {Moerland, Thomas M. and Broekens, Joost and Jonker, Catholijn M.},
	month = may,
	year = {2017},
	note = {arXiv: 1705.05172}
}

@article{ho_teaching_nodate,
	title = {Teaching by {Intervention}: {Working} {Backwards}, {Undoing} {Mistakes}, or {Correcting} {Mistakes}?},
	shorttitle = {Teaching by {Intervention}},
	url = {http://www.markkho.com/documents/teaching_by_intervention_cogsci.pdf},
	urldate = {2017-05-22TZ},
	author = {Ho, Mark K. and Littman, Michael L. and Austerweil, Joseph L.}
}

@article{valle_autonomous_2017,
	title = {Autonomous {Discovery} of {Motor} {Constraints} in an {Intrinsically}-{Motivated} {Vocal} {Learner}},
	volume = {PP},
	issn = {2379-8920},
	doi = {10.1109/TCDS.2017.2699578},
	abstract = {This work introduces new results on the modeling of early-vocal development using artificial intelligent cognitive architectures and a simulated vocal tract. The problem is addressed using intrinsically-motivated learning algorithms for autonomous sensorimotor exploration, a kind of algorithm belonging to the active learning architectures family. The artificial agent is able to autonomously select goals to explore its own sensorimotor system in regions where its competence to execute intended goals is improved. We propose to include a somatosensory system to provide a proprioceptive feedback signal to reinforce learning through the autonomous discovery of motor constraints. Constraints are represented by a somatosensory model which is unknown beforehand to the learner. Both the sensorimotor and somatosensory system are modeled using Gaussian mixture models. We argue that using an architecture which includes a somatosensory model would reduce redundancy in the sensorimotor model and drive the learning process more efficiently than algorithms taking into account only auditory feedback. The role of this proposed system is to predict whether an undesired collision within the vocal tract under a certain motor configuration is likely to occur. Thus, compromised motor configurations are rejected, guaranteeing that the agent is less prone to violate its own constraints.},
	number = {99},
	journal = {IEEE Transactions on Cognitive and Developmental Systems},
	author = {Valle, J. M. Acevedo and Angulo, C. and Moulin-Frier, C.},
	year = {2017},
	keywords = {Active learning, Biological system modeling, Early-vocal development, Gaussian mixture model, Gaussian mixture models, Intrinsic motivations, Production, Robot sensing systems, Sensorimotor exploration, Speech},
	pages = {1--1}
}

@article{gorur_toward_nodate,
	title = {Toward {Integrating} {Theory} of {Mind} into {Adaptive} {Decision}-{Making} of {Social} {Robots} to {Understand} {Human} {Intention}},
	url = {http://www.benjaminrosman.com/papers/hri17_ws.pdf},
	urldate = {2017-05-14TZ},
	author = {Görür, O. Can and Rosman, Benjamin and Hoffman, Guy and Albayrak, Şahin}
}

@inproceedings{law_designing_2017,
	address = {New York, NY, USA},
	series = {{CHI} {EA} '17},
	title = {Designing for {Curiosity}: {An} {Interdisciplinary} {Workshop}},
	isbn = {978-1-4503-4656-6},
	shorttitle = {Designing for {Curiosity}},
	url = {http://doi.acm.org/10.1145/3027063.3027064},
	doi = {10.1145/3027063.3027064},
	abstract = {Curiosity is a ubiquitous characteristic of humans and a central mechanism for motivating learning, information seeking behaviors, and sustained engagements with everyday artifacts, such as artistic creations, commercial products, interactive displays and persuasive health technologies, etc. Researchers from a variety of disciplines, e.g., psychology, education, economics, have studied the concept of curiosity, yet the question of how we can systematically design curiosity-inducing behaviors into user interfaces and interactions remains unexplored. In this workshop, our goal is to (i) bring together researchers from a variety of disciplines (e.g., psychology, AI/robotics, HCI, marketing) who study curiosity, as well as practitioners (e.g., architects, designers) who employ the concept of curiosity in their artistic creations, (ii) discuss the idea of curiosity from these diverse perspectives, and (iii) form a multidisciplinary community to build synergies for further collaboration.},
	urldate = {2017-05-14TZ},
	booktitle = {Proceedings of the 2017 {CHI} {Conference} {Extended} {Abstracts} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Law, Edith and Oudeyer, Pierre-Yves and Yin, Ming and Schaekermann, Mike and Williams, Alex C.},
	year = {2017},
	keywords = {curiosity, design, interdisciplinary},
	pages = {586--592}
}

@inproceedings{senft_leveraging_2017,
	title = {Leveraging {Human} {Inputs} in {Interactive} {Machine} {Learning} for {Human} {Robot} {Interaction}},
	url = {http://dl.acm.org/citation.cfm?id=3038385},
	urldate = {2017-05-08TZ},
	booktitle = {Proceedings of the {Companion} of the 2017 {ACM}/{IEEE} {International} {Conference} on {Human}-{Robot} {Interaction}},
	publisher = {ACM},
	author = {Senft, Emmanuel and Lemaignan, Séverin and Baxter, Paul E. and Belpaeme, Tony},
	year = {2017},
	pages = {281--282}
}

@article{mas_cobotique_nodate,
	title = {La cobotique},
	url = {https://hal.archives-ouvertes.fr/hal-01483705/document#page=16},
	urldate = {2017-05-08TZ},
	journal = {Master Recherche IC2A Ingénierie de la Cognition, de la Création et des Apprentissages},
	author = {Mas, Julien and Cecchi, Romane},
	pages = {11}
}

@article{mwangi_who_nodate,
	title = {Who is a {Better} {Tutor}? {Gaze} {Hints} with a {Human} or {Humanoid} {Tutor} in {Game} {Play}},
	shorttitle = {Who is a {Better} {Tutor}?},
	url = {http://www.idemployee.id.tue.nl/g.w.m.rauterberg/publications/HRI2017paper1.pdf},
	urldate = {2017-05-08TZ},
	author = {Mwangi, Eunice and Barakova, Emilia I. and Diaz, Marta and Catala, Andreu and Rauterberg, Matthias}
}

@inproceedings{forestier_autonomous_2016,
	title = {Autonomous exploration, active learning and human guidance with open-source {Poppy} humanoid robot platform and {Explauto} library},
	url = {https://hal.inria.fr/hal-01404399/document},
	abstract = {Our demonstration presents an open-source hardware and software platform which allows non-roboticists researchers to conduct machine learning experiments to benchmark algorithms for autonomous exploration and active learning. In particular, in addition to showing the general properties of the platform such as its modularity and usability, we will demonstrate the online functioning of a particular algorithm which allows efficient learning of multiple forward and inverse models and can leverage information from human guidance. A first aspect of our demonstration is to illustrate the ease of use of the 3D printed low-cost Poppy humanoid robotic platform, that allows non-roboticists to quickly set up and program robotic experiments. A second aspect is to show how the Explauto library allows systematic comparison and evaluation of active learning and exploration algorithms in sensorimotor spaces, through a Python API to select already implemented exploration algorithms. The third idea is to showcase Active Model Babbling, an efficient exploration algorithm dynamically choosing which task/goal space to explore and particular goals to reach, and integrating social guidance from humans in real time to drive exploration towards particular objects or actions. [Forestier and Oudeyer, 2016] Forestier, S. and Oudeyer, P.-Y. (2016). Modular active curiosity-driven discovery of tool use. In 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Daejeon, Korea. [Lapeyre et al., 2014] Lapeyre, M., Rouanet, P., Grizou, J., Nguyen, S., Depraetre, F., Le Falher, A., and Oudeyer, P.-Y. (2014). Poppy Project: Open-Source Fabrication of 3D Printed Humanoid Robot for Science, Education and Art. In Digital Intelligence 2014, page 6, Nantes, France. [Moulin-Frier et al., 2014] Moulin-Frier, C., Rouanet, P., Oudeyer, P.-Y., and others (2014). Explauto: an open- source Python library to study autonomous exploration in developmental robotics. In ICDL-Epirob-International Conference on Development and Learning, Epirob.},
	language = {en},
	urldate = {2017-05-08TZ},
	author = {Forestier, Sébastien and Mollard, Yoan and Caselli, Damien and Oudeyer, Pierre-Yves},
	month = dec,
	year = {2016}
}

@inproceedings{forestier_autonomous_2016-1,
	title = {Autonomous exploration, active learning and human guidance with open-source {Poppy} humanoid robot platform and {Explauto} library},
	url = {https://hal.inria.fr/hal-01404399/document},
	abstract = {Our demonstration presents an open-source hardware and software platform which allows non-roboticists researchers to conduct machine learning experiments to benchmark algorithms for autonomous exploration and active learning. In particular, in addition to showing the general properties of the platform such as its modularity and usability, we will demonstrate the online functioning of a particular algorithm which allows efficient learning of multiple forward and inverse models and can leverage information from human guidance. A first aspect of our demonstration is to illustrate the ease of use of the 3D printed low-cost Poppy humanoid robotic platform, that allows non-roboticists to quickly set up and program robotic experiments. A second aspect is to show how the Explauto library allows systematic comparison and evaluation of active learning and exploration algorithms in sensorimotor spaces, through a Python API to select already implemented exploration algorithms. The third idea is to showcase Active Model Babbling, an efficient exploration algorithm dynamically choosing which task/goal space to explore and particular goals to reach, and integrating social guidance from humans in real time to drive exploration towards particular objects or actions. [Forestier and Oudeyer, 2016] Forestier, S. and Oudeyer, P.-Y. (2016). Modular active curiosity-driven discovery of tool use. In 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Daejeon, Korea. [Lapeyre et al., 2014] Lapeyre, M., Rouanet, P., Grizou, J., Nguyen, S., Depraetre, F., Le Falher, A., and Oudeyer, P.-Y. (2014). Poppy Project: Open-Source Fabrication of 3D Printed Humanoid Robot for Science, Education and Art. In Digital Intelligence 2014, page 6, Nantes, France. [Moulin-Frier et al., 2014] Moulin-Frier, C., Rouanet, P., Oudeyer, P.-Y., and others (2014). Explauto: an open- source Python library to study autonomous exploration in developmental robotics. In ICDL-Epirob-International Conference on Development and Learning, Epirob.},
	language = {en},
	urldate = {2017-05-08TZ},
	author = {Forestier, Sébastien and Mollard, Yoan and Caselli, Damien and Oudeyer, Pierre-Yves},
	month = dec,
	year = {2016}
}

@article{oudeyer_intrinsic_2007,
	title = {Intrinsic motivation systems for autonomous mental development},
	volume = {11},
	url = {http://ieeexplore.ieee.org/abstract/document/4141061/},
	number = {2},
	urldate = {2017-04-11TZ},
	journal = {IEEE transactions on evolutionary computation},
	author = {Oudeyer, Pierre-Yves and Kaplan, Frdric and Hafner, Verena V.},
	year = {2007},
	pages = {265--286}
}

@article{oudeyer_what_2009,
	title = {What is intrinsic motivation? {A} typology of computational approaches},
	volume = {1},
	issn = {1662-5218},
	shorttitle = {What is intrinsic motivation?},
	url = {http://journal.frontiersin.org/article/10.3389/neuro.12.006.2007/full},
	doi = {10.3389/neuro.12.006.2007},
	abstract = {Intrinsic motivation, the causal mechanism for spontaneous exploration and curiosity, is a central concept in developmental psychology. It has been argued to be a crucial mechanism for open-ended cognitive development in humans, and as such has gathered a growing interest from developmental roboticists in the recent years. The goal of this paper is threefold. First, it provides a synthesis of the different approaches of intrinsic motivation in psychology. Second, by interpreting these approaches in a computational reinforcement learning framework, we argue that they are not operational and even sometimes inconsistent. Third, we set the ground for a systematic operational study of intrinsic motivation by presenting a formal typology of possible computational approaches. This typology is partly based on existing computational models, but also presents new ways of conceptualizing intrinsic motivation. We argue that this kind of computational typology might be useful for opening new avenues for research both in psychology and developmental robotics.},
	language = {English},
	urldate = {2017-04-11TZ},
	journal = {Frontiers in Neurorobotics},
	author = {Oudeyer, Pierre-Yves and Kaplan, Frederic},
	year = {2009},
	keywords = {Exploration, Reward, artificial intelligence, cognitive development, computational modeling, curiosity, developmental robotics, intrinsic motivation, reinforcement learning}
}

@article{hester_texplore:_2013,
	title = {{TEXPLORE}: real-time sample-efficient reinforcement learning for robots},
	volume = {90},
	shorttitle = {{TEXPLORE}},
	url = {http://link.springer.com/article/10.1007/s10994-012-5322-7},
	number = {3},
	urldate = {2017-04-07TZ},
	journal = {Machine learning},
	author = {Hester, Todd and Stone, Peter},
	year = {2013},
	pages = {385--429}
}

@inproceedings{hester_intrinsically_2012-1,
	title = {Intrinsically motivated model learning for a developing curious agent},
	url = {http://ieeexplore.ieee.org/abstract/document/6400802/},
	urldate = {2017-04-07TZ},
	booktitle = {Development and {Learning} and {Epigenetic} {Robotics} ({ICDL}), 2012 {IEEE} {International} {Conference} on},
	publisher = {IEEE},
	author = {Hester, Todd and Stone, Peter},
	year = {2012},
	pages = {1--6}
}

@inproceedings{barto_intrinsically_2004,
	title = {Intrinsically motivated learning of hierarchical collections of skills},
	url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.117.6436&rep=rep1&type=pdf},
	urldate = {2017-04-06TZ},
	booktitle = {Proceedings of the 3rd {International} {Conference} on {Development} and {Learning}},
	publisher = {Citeseer},
	author = {Barto, Andrew G. and Singh, Satinder and Chentanez, Nuttapong},
	year = {2004},
	pages = {112--19}
}

@article{lopes_active_2014,
	title = {Active learning for autonomous intelligent agents: {Exploration}, curiosity, and interaction},
	shorttitle = {Active learning for autonomous intelligent agents},
	url = {https://arxiv.org/abs/1403.1497},
	urldate = {2017-04-06TZ},
	journal = {arXiv preprint arXiv:1403.1497},
	author = {Lopes, Manuel and Montesano, Luis},
	year = {2014}
}

@inproceedings{baranes_maturationally-constrained_2010,
	title = {Maturationally-constrained competence-based intrinsically motivated learning},
	url = {http://ieeexplore.ieee.org/abstract/document/5578842/},
	urldate = {2017-04-06TZ},
	booktitle = {Development and {Learning} ({ICDL}), 2010 {IEEE} 9th {International} {Conference} on},
	publisher = {IEEE},
	author = {Baranes, Adrien and Oudeyer, Pierre-Yves},
	year = {2010},
	pages = {197--203}
}

@article{sutton_between_1999,
	title = {Between {MDPs} and semi-{MDPs}: {A} framework for temporal abstraction in reinforcement learning},
	volume = {112},
	shorttitle = {Between {MDPs} and semi-{MDPs}},
	url = {http://www.sciencedirect.com/science/article/pii/S0004370299000521},
	number = {1-2},
	urldate = {2017-04-06TZ},
	journal = {Artificial intelligence},
	author = {Sutton, Richard S. and Precup, Doina and Singh, Satinder},
	year = {1999},
	pages = {181--211}
}
@inproceedings{forestier_towards_2015,
	title = {Towards hierarchical curiosity-driven exploration of sensorimotor models},
	doi = {10.1109/DEVLRN.2015.7346146},
	abstract = {Curiosity-driven exploration mechanisms have been proposed to allow robots to actively explore high dimensional sensorimotor spaces in an open-ended manner [1], [2]. In such setups, competence-based intrinsic motivations show better results than knowledge-based exploration mechanisms which only monitor the learner's prediction performance [2], [3]. With competence-based intrinsic motivations, the learner explores its sensor space with a bias toward regions which are predicted to yield a high competence progress. Also, throughout its life, a developmental robot has to incrementally explore skills that add up to the hierarchy of previously learned skills, with a constraint being the cost of experimentation. Thus, a hierarchical exploration architecture could allow to reuse the sensorimotor models previously explored and to combine them to explore more efficiently new complex sensorimotor models. Here, we rely more specifically on the R-IAC and SAGG-RIAC series of architectures [3]. These architectures allow the learning of a single mapping between a motor and a sensor space with a competence-based intrinsic motivation. We describe some ways to extend these architectures with different tasks spaces that can be explored in a hierarchical manner, and mechanisms to handle this hierarchy of sensorimotor models that all need to be explored with an adequate amount of trials. We also describe an interactive task to evaluate the hierarchical learning mechanisms, where a robot has to explore its motor space in order to push an object to different locations. The robot can first explore how to make movements with its hand and then reuse this skill to explore the task of pushing an object.},
	booktitle = {2015 {Joint} {IEEE} {International} {Conference} on {Development} and {Learning} and {Epigenetic} {Robotics} ({ICDL}-{EpiRob})},
	author = {Forestier, S. and Oudeyer, P. Y.},
	month = aug,
	year = {2015},
	pages = {234--235}
}

@inproceedings{subramanian_learning_2011,
	title = {Learning options through human interaction},
	url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.357.8754&rep=rep1&type=pdf},
	urldate = {2017-03-29TZ},
	booktitle = {2011 {IJCAI} {Workshop} on {Agents} {Learning} {Interactively} from {Human} {Teachers} ({ALIHT})},
	publisher = {Citeseer},
	author = {Subramanian, Kaushik and Isbell, Charles and Thomaz, Andrea},
	year = {2011}
}

@misc{noauthor_kvfrans_nodate,
	title = {kvfrans ({Kevin} {Frans})},
	url = {https://github.com/kvfrans},
	abstract = {kvfrans has 87 repositories available. Follow their code on GitHub.},
	urldate = {2017-02-10TZ},
	journal = {GitHub}
}

@misc{noauthor_kvfrans_nodate-1,
	title = {kvfrans ({Kevin} {Frans})},
	url = {https://github.com/kvfrans},
	abstract = {kvfrans has 87 repositories available. Follow their code on GitHub.},
	urldate = {2017-02-10TZ},
	journal = {GitHub}
}

@article{peters_natural_2008,
	title = {Natural actor-critic},
	volume = {71},
	url = {http://www.sciencedirect.com/science/article/pii/S0925231208000532},
	number = {7},
	urldate = {2017-02-10TZ},
	journal = {Neurocomputing},
	author = {Peters, Jan and Schaal, Stefan},
	year = {2008},
	pages = {1180--1190}
}

@article{bhatnagar_natural_2009,
	title = {Natural actor-critic algorithms},
	volume = {45},
	url = {https://hal.inria.fr/hal-00840470/},
	number = {11},
	urldate = {2017-02-10TZ},
	journal = {Automatica},
	author = {Bhatnagar, Shalabh and Sutton, Richard and Ghavamzadeh, Mohammad and Lee, Mark},
	year = {2009}
}

@article{grondman_survey_2012,
	title = {A survey of actor-critic reinforcement learning: {Standard} and natural policy gradients},
	volume = {42},
	shorttitle = {A survey of actor-critic reinforcement learning},
	url = {http://ieeexplore.ieee.org/abstract/document/6392457/},
	number = {6},
	urldate = {2017-02-10TZ},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
	author = {Grondman, Ivo and Busoniu, Lucian and Lopes, Gabriel AD and Babuska, Robert},
	year = {2012},
	pages = {1291--1307}
}

@inproceedings{sutton_policy_1999,
	title = {Policy gradient methods for reinforcement learning with function approximation.},
	volume = {99},
	url = {https://papers.nips.cc/paper/1713-policy-gradient-methods-for-reinforcement-learning-with-function-approximation.pdf},
	urldate = {2017-02-10TZ},
	booktitle = {{NIPS}},
	author = {Sutton, Richard S. and McAllester, David A. and Singh, Satinder P. and Mansour, Yishay and {others}},
	year = {1999},
	pages = {1057--1063}
}

@article{kaplan_challenges_2006,
	title = {The challenges of joint attention},
	volume = {7},
	url = {http://www.jbe-platform.com/content/journals/10.1075/is.7.2.04kap},
	number = {2},
	urldate = {2017-01-31TZ},
	journal = {Interaction Studies},
	author = {Kaplan, Frederic and Hafner, Verena V.},
	year = {2006},
	pages = {135--169}
}

@article{grondman_survey_2012-1,
	title = {A survey of actor-critic reinforcement learning: {Standard} and natural policy gradients},
	volume = {42},
	shorttitle = {A survey of actor-critic reinforcement learning},
	url = {http://ieeexplore.ieee.org/abstract/document/6392457/},
	number = {6},
	urldate = {2017-01-29TZ},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
	author = {Grondman, Ivo and Busoniu, Lucian and Lopes, Gabriel AD and Babuska, Robert},
	year = {2012},
	pages = {1291--1307}
}

@article{ferreira_attentional_2014,
	title = {Attentional {Mechanisms} for {Socially} {Interactive} {Robots} \#x2013;{A} {Survey}},
	volume = {6},
	issn = {1943-0604},
	doi = {10.1109/TAMD.2014.2303072},
	abstract = {This review intends to provide an overview of the state of the art in the modeling and implementation of automatic attentional mechanisms for socially interactive robots. Humans assess and exhibit intentionality by resorting to multisensory processes that are deeply rooted within low-level automatic attention-related mechanisms of the brain. For robots to engage with humans properly, they should also be equipped with similar capabilities. Joint attention, the precursor of many fundamental types of social interactions, has been an important focus of research in the past decade and a half, therefore providing the perfect backdrop for assessing the current status of state-of-the-art automatic attentional-based solutions. Consequently, we propose to review the influence of these mechanisms in the context of social interaction in cutting-edge research work on joint attention. This will be achieved by summarizing the contributions already made in these matters in robotic cognitive systems research, by identifying the main scientific issues to be addressed by these contributions and analyzing how successful they have been in this respect, and by consequently drawing conclusions that may suggest a roadmap for future successful research efforts.},
	number = {2},
	journal = {IEEE Transactions on Autonomous Mental Development},
	author = {Ferreira, J. F. and Dias, J.},
	month = jun,
	year = {2014},
	pages = {110--125}
}

@inproceedings{mirian_comparing_2008,
	title = {Comparing learning attention control in perceptual and decision space},
	url = {http://link.springer.com/10.1007%2F978-3-642-00582-4_18},
	urldate = {2017-01-24TZ},
	booktitle = {International {Workshop} on {Attention} in {Cognitive} {Systems}},
	publisher = {Springer},
	author = {Mirian, Maryam S. and Ahmadabadi, Majid Nili and Araabi, Babak N. and Siegwart, Ronald R.},
	year = {2008},
	pages = {242--256}
}

@inproceedings{shariatpanahi_biologically_2007,
	title = {Biologically inspired framework for learning and abstract representation of attention control},
	url = {http://link.springer.com/10.1007/978-3-540-77343-6_20},
	urldate = {2017-01-24TZ},
	booktitle = {International {Workshop} on {Attention} in {Cognitive} {Systems}},
	publisher = {Springer},
	author = {Shariatpanahi, Hadi Fatemi and Ahmadabadi, Majid Nili},
	year = {2007},
	pages = {307--324}
}

@inproceedings{knox_interactively_2009,
	title = {Interactively shaping agents via human reinforcement: {The} {TAMER} framework},
	shorttitle = {Interactively shaping agents via human reinforcement},
	url = {http://dl.acm.org/citation.cfm?id=1597738},
	urldate = {2017-01-16TZ},
	booktitle = {Proceedings of the fifth international conference on {Knowledge} capture},
	publisher = {ACM},
	author = {Knox, W. Bradley and Stone, Peter},
	year = {2009},
	pages = {9--16}
}

@article{adamson_still_2003,
	title = {The still face: {A} history of a shared experimental paradigm},
	volume = {4},
	shorttitle = {The still face},
	url = {http://www.tandfonline.com/doi/abs/10.1207/S15327078IN0404_01},
	number = {4},
	urldate = {2017-01-16TZ},
	journal = {Infancy},
	author = {Adamson, Lauren B. and Frick, Janet E.},
	year = {2003},
	pages = {451--473}
}

@article{parrott_infants_1989,
	title = {Infants' {Expectations} in {Play}: {The} {Joy} of {Peek}-a-boo},
	volume = {3},
	issn = {0269-9931},
	shorttitle = {Infants' {Expectations} in {Play}},
	url = {http://dx.doi.org/10.1080/02699938908412710},
	doi = {10.1080/02699938908412710},
	abstract = {The role of expectations in infants' enjoyment of play was studied by observing their smiling, laughter, and eyebrow raises during a peek-a-boo game that contained occasional trick trials. In Experiments 1 and 2, 6, 7-, and 8-month-olds (n = 29) participated in a peek-a-boo game in which, on occasional “person-switch” trials, one adult hid and a second adult “reappeared” in his or her place. Infants in all age groups smiled less following person-switch reappearances than following normal ones, with the difference increasing with age. In Experiment 3, 7-month-old infants (n = 10) played a peek-a-boo game in which the adult occasionally reappeared in a different location. Smiling decreased for “location switches” just as it had for person switches. Infants in all age groups were more likely to exhibit eyebrow raises following trick reappearances than following normal ones. These findings suggest that infants as young as 6 months have expectations about the identity and location of a returning person, that conformity to these expectations contributes to infants' enjoyment of games such as peek-a-boo, and that infants of this age may not yet enjoy deviations from their expectations. Implications are discussed for theories of playful enjoyment, for the cognitive antecedents of positive affect, and for cognitive development.},
	number = {4},
	urldate = {2017-01-16TZ},
	journal = {Cognition and Emotion},
	author = {Parrott, W. Gerrod and Gleitman, Henry},
	month = oct,
	year = {1989},
	pages = {291--311}
}

@book{sutton_reinforcement_1998,
	title = {Reinforcement learning: {An} introduction},
	volume = {1},
	shorttitle = {Reinforcement learning},
	url = {http://www.cell.com/trends/cognitive-sciences/pdf/S1364-6613(99)01331-5.pdf},
	number = {1},
	urldate = {2017-01-16TZ},
	publisher = {MIT press Cambridge},
	author = {Sutton, Richard S. and Barto, Andrew G.},
	year = {1998}
}

@article{noauthor_notitle_nodate
}

@inproceedings{abbeel_apprenticeship_2004,
	title = {Apprenticeship learning via inverse reinforcement learning},
	url = {http://dl.acm.org/citation.cfm?id=1015430},
	urldate = {2016-10-31TZ},
	booktitle = {Proceedings of the twenty-first international conference on {Machine} learning},
	publisher = {ACM},
	author = {Abbeel, Pieter and Ng, Andrew Y.},
	year = {2004},
	note = {ICML},
	pages = {1}
}

@inproceedings{abbeel_apprenticeship_2004-1,
	address = {New York, NY, USA},
	series = {{ICML} '04},
	title = {Apprenticeship {Learning} via {Inverse} {Reinforcement} {Learning}},
	isbn = {978-1-58113-838-2},
	url = {http://doi.acm.org/10.1145/1015330.1015430},
	doi = {10.1145/1015330.1015430},
	abstract = {We consider learning in a Markov decision process where we are not explicitly given a reward function, but where instead we can observe an expert demonstrating the task that we want to learn to perform. This setting is useful in applications (such as the task of driving) where it may be difficult to write down an explicit reward function specifying exactly how different desiderata should be traded off. We think of the expert as trying to maximize a reward function that is expressible as a linear combination of known features, and give an algorithm for learning the task demonstrated by the expert. Our algorithm is based on using "inverse reinforcement learning" to try to recover the unknown reward function. We show that our algorithm terminates in a small number of iterations, and that even though we may never recover the expert's reward function, the policy output by the algorithm will attain performance close to that of the expert, where here performance is measured with respect to the expert's unknown reward function.},
	urldate = {2017-01-10TZ},
	booktitle = {Proceedings of the {Twenty}-first {International} {Conference} on {Machine} {Learning}},
	publisher = {ACM},
	author = {Abbeel, Pieter and Ng, Andrew Y.},
	year = {2004},
	pages = {1--}
}

@misc{noauthor_better_nodate,
	title = {better bibtex abbreviation - {Recherche} {Google}},
	url = {https://www.google.fr/search?sourceid=chrome-psyapi2&ion=1&espv=2&ie=UTF-8&q=better%20bibtex%20abbreviation&oq=better%20bibtex%20abbreviation&aqs=chrome..69i57j69i60l2.10107j0j1},
	urldate = {2017-01-10TZ}
}

@inproceedings{chentanez_intrinsically_2004,
	title = {Intrinsically motivated reinforcement learning},
	url = {http://machinelearning.wustl.edu/mlpapers/paper_files/NIPS2005_724.pdf},
	urldate = {2016-12-08TZ},
	booktitle = {Advances in neural information processing systems},
	author = {Chentanez, Nuttapong and Barto, Andrew G. and Singh, Satinder P.},
	year = {2004},
	pages = {1281--1288}
}

@article{fern_decision-theoretic_2014,
	title = {A decision-theoretic model of assistance},
	volume = {50},
	url = {http://dl.acm.org/citation.cfm?id=2693071},
	number = {1},
	urldate = {2016-12-20TZ},
	journal = {Journal of Artificial Intelligence Research},
	author = {Fern, Alan and Natarajan, Sriraam and Judah, Kshitij and Tadepalli, Prasad},
	year = {2014},
	pages = {71--104}
}

@inproceedings{fern_computational_2010,
	title = {A computational decision theory for interactive assistants},
	url = {http://papers.nips.cc/paper/4052-a-computational-decision-theory-for-interactive-assistants},
	urldate = {2016-12-20TZ},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Fern, Alan and Tadepalli, Prasad},
	year = {2010},
	pages = {577--585}
}

@article{pantelis_inferring_2014,
	title = {Inferring the intentional states of autonomous virtual agents},
	volume = {130},
	url = {http://www.sciencedirect.com/science/article/pii/S0010027713002291},
	number = {3},
	urldate = {2016-12-13TZ},
	journal = {Cognition},
	author = {Pantelis, Peter C. and Baker, Chris L. and Cholewiak, Steven A. and Sanik, Kevin and Weinstein, Ari and Wu, Chia-Chien and Tenenbaum, Joshua B. and Feldman, Jacob},
	year = {2014},
	pages = {360--379}
}

@article{baker_modeling_2014,
	title = {Modeling human plan recognition using bayesian theory of mind},
	url = {http://www.hpctoday.com/files/docs/pdfs/plan_activity_and_intent_recognition.pdf},
	urldate = {2016-12-13TZ},
	journal = {Plan, activity, and intent recognition: Theory and practice},
	author = {Baker, Chris L. and Tenenbaum, Joshua B.},
	year = {2014},
	pages = {177--204}
}

@article{diaconescu_inferring_2014,
	title = {Inferring on the {Intentions} of {Others} by {Hierarchical} {Bayesian} {Learning}},
	volume = {10},
	issn = {1553-7358},
	url = {http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003810},
	doi = {10.1371/journal.pcbi.1003810},
	abstract = {Author Summary The ability to decode another person's intentions is a critical component of social interactions. This is particularly important when we have to make decisions based on someone else's advice. Our research proposes that this complex cognitive skill (social learning) can be translated into a mathematical model, which prescribes a mechanism for mentally simulating another person's intentions. This study demonstrates that this process can be parsimoniously described as the deployment of hierarchical learning. In other words, participants learn about two quantities: the intentions of the person they interact with and the veracity of the recommendations they offer. As participants become more and more confident about their representation of the other's intentions, they make decisions more in accordance with the advice they receive. Importantly, our modeling framework captures individual differences in the social learning process: The estimated “learning fingerprint” can predict other aspects of participants' behavior, such as their perspective-taking abilities and their explicit ratings of the adviser's level of trustworthiness. The present modeling approach can be further applied in the context of psychiatry to identify maladaptive learning processes in disorders where social learning processes are particularly impaired, such as schizophrenia.},
	number = {9},
	urldate = {2016-12-13TZ},
	journal = {PLOS Computational Biology},
	author = {Diaconescu, Andreea O. and Mathys, Christoph and Weber, Lilian A. E. and Daunizeau, Jean and Kasper, Lars and Lomakina, Ekaterina I. and Fehr, Ernst and Stephan, Klaas E.},
	month = sep,
	year = {2014},
	pages = {e1003810}
}

@inproceedings{baker_bayesian_2011,
	title = {Bayesian theory of mind: {Modeling} joint belief-desire attribution},
	shorttitle = {Bayesian theory of mind},
	url = {http://mindmodeling.org/cogsci2011/papers/0583/paper0583.pdf},
	urldate = {2016-12-13TZ},
	booktitle = {Proceedings of the thirty-second annual conference of the cognitive science society},
	author = {Baker, Chris L. and Saxe, Rebecca R. and Tenenbaum, Joshua B.},
	year = {2011},
	pages = {2469--2474}
}

@inproceedings{ullman_help_2009,
	title = {Help or hinder: {Bayesian} models of social goal inference},
	shorttitle = {Help or hinder},
	url = {http://papers.nips.cc/paper/3747-help-or-hinder-bayesian-models-of-social-goal-inference},
	urldate = {2016-12-13TZ},
	booktitle = {Advances in neural information processing systems},
	author = {Ullman, Tomer and Baker, Chris and Macindoe, Owen and Evans, Owain and Goodman, Noah and Tenenbaum, Joshua B.},
	year = {2009},
	pages = {1874--1882}
}

@inproceedings{baker_theory-based_2008,
	title = {Theory-based social goal inference},
	url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.154.2746&rep=rep1&type=pdf},
	urldate = {2016-12-13TZ},
	booktitle = {Proceedings of the thirtieth annual conference of the cognitive science society},
	publisher = {Citeseer},
	author = {Baker, Chris L. and Goodman, Noah D. and Tenenbaum, Joshua B.},
	year = {2008},
	pages = {1447--1452}
}

@article{georgeon_demonstrating_2013,
	title = {Demonstrating sensemaking emergence in artificial agents: {A} method and an example},
	volume = {5},
	shorttitle = {Demonstrating sensemaking emergence in artificial agents},
	url = {http://www.worldscientific.com/doi/abs/10.1142/S1793843013500029},
	number = {02},
	urldate = {2016-12-08TZ},
	journal = {International Journal of Machine Consciousness},
	author = {Georgeon, Olivier L. and Marshall, James B.},
	year = {2013},
	pages = {131--144}
}

@inproceedings{georgeon_interactional_2012,
	title = {Interactional motivation in artificial systems: {Between} extrinsic and intrinsic motivation},
	shorttitle = {Interactional motivation in artificial systems},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6400833},
	urldate = {2016-12-08TZ},
	booktitle = {2012 {IEEE} {International} {Conference} on {Development} and {Learning} and {Epigenetic} {Robotics} ({ICDL})},
	publisher = {IEEE},
	author = {Georgeon, Olivier L. and Marshall, James B. and Gay, Simon},
	year = {2012},
	pages = {1--2}
}

@inproceedings{koppula_physically_2014,
	title = {Physically grounded spatio-temporal object affordances},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-10578-9_54},
	urldate = {2016-12-07TZ},
	booktitle = {European {Conference} on {Computer} {Vision}},
	publisher = {Springer},
	author = {Koppula, Hema S. and Saxena, Ashutosh},
	year = {2014},
	pages = {831--847}
}

@inproceedings{subramanian_exploration_2016,
	title = {Exploration from {Demonstration} for {Interactive} {Reinforcement} {Learning}},
	url = {http://dl.acm.org/citation.cfm?id=2936990},
	urldate = {2016-12-07TZ},
	booktitle = {Proceedings of the 2016 {International} {Conference} on {Autonomous} {Agents} \& {Multiagent} {Systems}},
	publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
	author = {Subramanian, Kaushik and Isbell Jr, Charles L. and Thomaz, Andrea L.},
	year = {2016},
	pages = {447--456}
}

@article{cobo_rus_leveraging_2013,
	title = {Leveraging attention focus for effective reinforcement learning in complex domains},
	url = {https://smartech.gatech.edu/handle/1853/47618},
	urldate = {2016-12-07TZ},
	author = {Cobo Rus, Luis Carlos},
	year = {2013}
}

@inproceedings{mohammad_learning_2010,
	title = {Learning interaction protocols using {Augmented} {Baysian} {Networks} applied to guided navigation},
	doi = {10.1109/IROS.2010.5651719},
	abstract = {Research in robot navigation usually concentrates on implementing navigation algorithms that allow the robot to navigate without human aid. In many real world situations, it is desirable that the robot is able to understand natural gestures from its user or partner and use this understanding to guide its navigation. Some algorithms already exist for learning natural gestures and/or their associated actions but most of these systems does not allow the robot to automatically generate the associated controller that allows it to actually navigate in the real environment. Furthermore, a technique is needed to combine the gestures/actions learned from interacting with multiple users or partners. This paper resolves these two issues and provides a complete system that allows the robot to learn interaction protocols and act upon them using only unsupervised learning techniques and enables it to combine the protocols learned from multiple users/partners. The proposed approach is general and can be applied to other interactive tasks as well. This paper also provides a real world experiment involving 18 subjects and 72 sessions that supports the ability of the proposed system to learn the needed gestures and to improve its knowledge of different gestures and their associations to actions over time.},
	booktitle = {2010 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	author = {Mohammad, Y. and Nishida, T.},
	month = oct,
	year = {2010},
	keywords = {Bayes methods, augmented Bayesian networks, gesture analysis, gesture recognition, guided navigation, learning interaction protocols, path planning, robot navigation, unsupervised learning, unsupervised learning techniques},
	pages = {4119--4126}
}

@misc{center_for_history_and_new_media_guide_nodate,
	title = {Guide rapide pour débuter},
	url = {http://zotero.org/support/quick_start_guide},
	author = {{Center for History and New Media}}
}

@article{rolf_where_2014,
	title = {Where do goals come from? {A} generic approach to autonomous goal-system development},
	shorttitle = {Where do goals come from?},
	url = {http://arxiv.org/abs/1410.5557},
	urldate = {2016-12-05TZ},
	journal = {arXiv preprint arXiv:1410.5557},
	author = {Rolf, Matthias and Asada, Minoru},
	year = {2014}
}

@article{rolf_explorative_2014,
	title = {Explorative learning of inverse models: {A} theoretical perspective},
	volume = {131},
	issn = {0925-2312},
	shorttitle = {Explorative learning of inverse models},
	url = {http://www.sciencedirect.com/science/article/pii/S0925231213010977},
	doi = {10.1016/j.neucom.2013.04.050},
	abstract = {We investigate the role of redundancy for exploratory learning of inverse functions, where an agent learns to achieve goals by performing actions and observing outcomes. We present an analysis of linear redundancy and investigate goal-directed exploration approaches, which are empirically successful, but hardly theorized except negative results for special cases, and prove convergence to the optimal solution. We show that the learning curves of such processes are intrinsically low-dimensional and S-shaped, which explains previous empirical findings, and finally compare our results to non-linear domains.},
	urldate = {2016-12-05TZ},
	journal = {Neurocomputing},
	author = {Rolf, Matthias and Steil, Jochen J.},
	month = may,
	year = {2014},
	keywords = {Exploration, Goal babbling, Inverse models, Motor learning, Redundancy},
	pages = {2--14}
}

@phdthesis{sao_mai_curious_2014,
	title = {A {Curious} {Robot} {Learner} for {Interactive} {Goal}-{Babbling}},
	url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.636.1176&rep=rep1&type=pdf},
	urldate = {2016-12-05TZ},
	school = {Citeseer},
	author = {Sao Mai, Nguyen},
	year = {2014}
}

@article{rolf_intentional_nodate,
	title = {Intentional {Goals}: {Affordances} with {Values}?},
	shorttitle = {Intentional {Goals}},
	url = {http://vislab.isr.ist.utl.pt/wp-content/uploads/2015/10/RolfAsada2015-Affordance.pdf},
	urldate = {2016-12-05TZ},
	author = {Rolf, Matthias and Asada, Minoru}
}

@inproceedings{paletta_perception_2007,
	title = {Perception and developmental learning of affordances in autonomous robots},
	url = {http://link.springer.com/chapter/10.1007/978-3-540-74565-5_19},
	urldate = {2016-12-05TZ},
	booktitle = {Annual {Conference} on {Artificial} {Intelligence}},
	publisher = {Springer},
	author = {Paletta, Lucas and Fritz, Gerald and Kintzler, Florian and Irran, Jörg and Dorffner, Georg},
	year = {2007},
	pages = {235--250}
}

@inproceedings{cruz_improving_2014,
	title = {Improving reinforcement learning with interactive feedback and affordances},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6982975},
	urldate = {2016-12-05TZ},
	booktitle = {4th {International} {Conference} on {Development} and {Learning} and on {Epigenetic} {Robotics}},
	publisher = {IEEE},
	author = {Cruz, Francisco and Magg, Sven and Weber, Cornelius and Wermter, Stefan},
	year = {2014},
	pages = {165--170}
}

@article{lang_planning_2010,
	title = {Planning with noisy probabilistic relational rules},
	volume = {39},
	url = {http://www.aaai.org/Papers/JAIR/Vol39/JAIR-3901.pdf},
	number = {1},
	urldate = {2016-12-02TZ},
	journal = {Journal of Artificial Intelligence Research},
	author = {Lang, Tobias and Toussaint, Marc},
	year = {2010},
	pages = {1--49}
}

@article{antunes_robotic_nodate,
	title = {Robotic tool use and problem solving based on probabilistic planning and learned affordances},
	url = {http://vislab.isr.ist.utl.pt/wp-content/uploads/2015/11/antunes_IROS_2015_ws_affordances.pdf},
	urldate = {2016-12-02TZ},
	author = {Antunes, Alexandre and Saponaro, Giovanni and Dehban, Atabak and Jamone, Lorenzo and Ventura, Rodrigo and Bernardino, Alexandre and Santos-Victor, José}
}

@article{cruz_contextual_nodate,
	title = {Contextual {Affordances} for {Action}-{Effect} {Prediction} in a {Robotic}-{Cleaning} {Task}},
	url = {http://www.academia.edu/download/45307348/Cruz_affordances_IROS2015.pdf},
	urldate = {2016-12-02TZ},
	author = {Cruz, Francisco and Parisi, German I. and Wermter, Stefan}
}

@inproceedings{rolf_explorative_2012,
	title = {Explorative learning of right inverse functions: theoretical implications of redundancy},
	shorttitle = {Explorative learning of right inverse functions},
	url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.680.6041&rep=rep1&type=pdf#page=6},
	urldate = {2016-12-02TZ},
	booktitle = {Workshop {New} {Challenges} in {Neural} {Computation} 2012},
	publisher = {Citeseer},
	author = {Rolf, Matthias and Steil, Jochen J.},
	year = {2012},
	pages = {6}
}

@article{rolf_goal_2010,
	title = {Goal babbling permits direct learning of inverse kinematics},
	volume = {2},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5535131},
	number = {3},
	urldate = {2016-12-02TZ},
	journal = {IEEE Transactions on Autonomous Mental Development},
	author = {Rolf, Matthias and Steil, Jochen J. and Gienger, Michael},
	year = {2010},
	pages = {216--229}
}

@article{baranes_active_2013,
	title = {Active learning of inverse models with intrinsically motivated goal exploration in robots},
	volume = {61},
	url = {http://www.sciencedirect.com/science/article/pii/S0921889012000644},
	number = {1},
	urldate = {2016-12-02TZ},
	journal = {Robotics and Autonomous Systems},
	author = {Baranes, Adrien and Oudeyer, Pierre-Yves},
	year = {2013},
	pages = {49--73}
}
@article{oudeyer_intrinsic_2007,
	title = {Intrinsic motivation systems for autonomous mental development},
	volume = {11},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4141061},
	number = {2},
	urldate = {2016-12-02TZ},
	journal = {IEEE transactions on evolutionary computation},
	author = {Oudeyer, Pierre-Yves and Kaplan, Frdric and Hafner, Verena V.},
	year = {2007},
	pages = {265--286}
}

@article{rolf_goal_2012,
	title = {Goal babbling: a new concept for early sensorimotor exploration},
	volume = {11},
	shorttitle = {Goal babbling},
	url = {http://corwww.techfak.uni-bielefeld.de/system/files/RolfSteil2012-DevRob-GoalBabbling.pdf},
	urldate = {2016-12-02TZ},
	journal = {Osaka},
	author = {Rolf, Matthias and Steil, Jochen J. and {others}},
	year = {2012},
	pages = {2012}
}

@article{bhatnagar_natural_2009,
	title = {Natural actor–critic algorithms},
	volume = {45},
	url = {http://www.sciencedirect.com/science/article/pii/S0005109809003549},
	number = {11},
	urldate = {2016-12-01TZ},
	journal = {Automatica},
	author = {Bhatnagar, Shalabh and Sutton, Richard S. and Ghavamzadeh, Mohammad and Lee, Mark},
	year = {2009},
	pages = {2471--2482}
}

@article{macglashan_convergent_nodate,
	title = {Convergent {Actor} {Critic} by {Humans}},
	url = {http://irll.eecs.wsu.edu/wp-content/papercite-data/pdf/2016iros-hrc-macglashan.pdf},
	urldate = {2016-12-01TZ},
	author = {MacGlashan, James and Littman, Michael L. and Roberts, David L. and Loftin, Robert and Peng, Bei and Taylor, Matthew E.}
}

@article{tagniguchi_multimodal_2015,
	title = {Multimodal {Hierarchical} {Dirichlet} {Process}-based {Active} {Perception}},
	url = {https://pdfs.semanticscholar.org/3298/0a97cdab6d019299d055a685c0ffe24dd4d9.pdf},
	urldate = {2016-11-25TZ},
	journal = {arXiv preprint arXiv:1510.00331},
	author = {Tagniguchi, T. and Takano, Toshiaki and Yoshino, Ryo},
	year = {2015}
}

@inproceedings{stark_functional_2008,
	title = {Functional object class detection based on learned affordance cues},
	url = {http://link.springer.com/chapter/10.1007/978-3-540-79547-6_42},
	urldate = {2016-11-25TZ},
	booktitle = {International conference on computer vision systems},
	publisher = {Springer},
	author = {Stark, Michael and Lies, Philipp and Zillich, Michael and Wyatt, Jeremy and Schiele, Bernt},
	year = {2008},
	pages = {435--444}
}

@article{ugur_goal_2011,
	title = {Goal emulation and planning in perceptual space using learned affordances},
	volume = {59},
	url = {http://www.sciencedirect.com/science/article/pii/S0921889011000741},
	number = {7},
	urldate = {2016-11-25TZ},
	journal = {Robotics and Autonomous Systems},
	author = {Ugur, Emre and Oztop, Erhan and Sahin, Erol},
	year = {2011},
	pages = {580--595}
}

@inproceedings{torralba_learning_2011,
	title = {Learning to learn with compound hd models},
	url = {http://papers.nips.cc/paper/4474-learning-to-learn-with-compound-hd-models},
	urldate = {2016-11-25TZ},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Torralba, Antonio and Tenenbaum, Joshua B. and Salakhutdinov, Ruslan R.},
	year = {2011},
	pages = {2061--2069}
}

@inproceedings{tadepalli_relational_2004,
	title = {Relational reinforcement learning: {An} overview},
	shorttitle = {Relational reinforcement learning},
	url = {https://lirias.kuleuven.be/handle/123456789/131145},
	urldate = {2016-11-24TZ},
	booktitle = {Proceedings of the {ICML}-2004 {Workshop} on {Relational} {Reinforcement} {Learning}},
	author = {Tadepalli, Prasad and Givan, Robert and Driessens, Kurt},
	year = {2004},
	pages = {1--9}
}

@article{starzyk_needs_2016,
	title = {Needs, {Pains}, and {Motivations} in {Autonomous} {Agents}},
	url = {http://ncn.wsiz.rzeszow.pl/wp-content/uploads/2013/10/Needs-Pains-Motivations-Revised.pdf},
	urldate = {2016-11-23TZ},
	journal = {IEEE Trans. Neural Networks Learn. Syst},
	author = {Starzyk, Janusz A. and Graham, James and Puzio, Leszek},
	year = {2016}
}

@inproceedings{moulin-frier_explauto:_2014,
	title = {Explauto: an open-source {Python} library to study autonomous exploration in developmental robotics},
	shorttitle = {Explauto},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6982976},
	urldate = {2016-11-23TZ},
	booktitle = {4th {International} {Conference} on {Development} and {Learning} and on {Epigenetic} {Robotics}},
	publisher = {IEEE},
	author = {Moulin-Frier, Clément and Rouanet, Pierre and Oudeyer, Pierre-Yves},
	year = {2014},
	pages = {171--172}
}

@inproceedings{moulin-frier_exploration_2013,
	title = {Exploration strategies in developmental robotics: a unified probabilistic framework},
	shorttitle = {Exploration strategies in developmental robotics},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6652535},
	urldate = {2016-11-23TZ},
	booktitle = {2013 {IEEE} {Third} {Joint} {International} {Conference} on {Development} and {Learning} and {Epigenetic} {Robotics} ({ICDL})},
	publisher = {IEEE},
	author = {Moulin-Frier, Clément and Oudeyer, Pierre-Yves},
	year = {2013},
	pages = {1--6}
}

@inproceedings{kulick_active_2013,
	title = {Active {Learning} for {Teaching} a {Robot} {Grounded} {Relational} {Symbols}.},
	url = {http://www.ijcai.org/Proceedings/13/Papers/217.pdf},
	urldate = {2016-11-23TZ},
	booktitle = {{IJCAI}},
	author = {Kulick, Johannes and Toussaint, Marc and Lang, Tobias and Lopes, Manuel},
	year = {2013}
}

@article{austermann_teaching_2010,
	title = {Teaching a pet-robot to understand user feedback through interactive virtual training tasks},
	volume = {20},
	url = {http://link.springer.com/article/10.1007/s10458-009-9095-8},
	number = {1},
	urldate = {2016-11-23TZ},
	journal = {Autonomous agents and multi-agent systems},
	author = {Austermann, Anja and Yamada, Seiji},
	year = {2010},
	pages = {85--104}
}

@inproceedings{boucenna_development_2011,
	title = {Development of joint attention and social referencing},
	volume = {2},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6037317},
	urldate = {2016-11-23TZ},
	booktitle = {2011 {IEEE} {International} {Conference} on {Development} and {Learning} ({ICDL})},
	publisher = {IEEE},
	author = {Boucenna, Sofiane and Gaussier, Philippe and Hafemeister, Laurence},
	year = {2011},
	pages = {1--6}
}

@inproceedings{osorio_gaussian_2010,
	title = {Gaussian mixture models for affordance learning using {Bayesian} {Networks}},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5650297},
	urldate = {2016-11-23TZ},
	booktitle = {Intelligent {Robots} and {Systems} ({IROS}), 2010 {IEEE}/{RSJ} {International} {Conference} on},
	publisher = {IEEE},
	author = {Osório, Pedro and Bernardino, Alexandre and Martinez-Cantin, Ruben and Santos-Victor, José},
	year = {2010},
	pages = {4432--4437}
}

@article{montesano_learning_2008,
	title = {Learning object affordances: {From} sensory–motor coordination to imitation},
	volume = {24},
	shorttitle = {Learning object affordances},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4456755},
	number = {1},
	urldate = {2016-11-23TZ},
	journal = {IEEE Transactions on Robotics},
	author = {Montesano, Luis and Lopes, Manuel and Bernardino, Alexandre and Santos-Victor, José},
	year = {2008},
	pages = {15--26}
}

@article{noda_multimodal_2014,
	title = {Multimodal integration learning of robot behavior using deep neural networks},
	volume = {62},
	url = {http://www.sciencedirect.com/science/article/pii/S0921889014000396},
	number = {6},
	urldate = {2016-11-23TZ},
	journal = {Robotics and Autonomous Systems},
	author = {Noda, Kuniaki and Arie, Hiroaki and Suga, Yuki and Ogata, Tetsuya},
	year = {2014},
	pages = {721--736}
}

@inproceedings{moldovan_use_2013,
	title = {On the use of probabilistic relational affordance models for sequential manipulation tasks in robotics},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6630737},
	urldate = {2016-11-23TZ},
	booktitle = {Robotics and {Automation} ({ICRA}), 2013 {IEEE} {International} {Conference} on},
	publisher = {IEEE},
	author = {Moldovan, Bogdan and Moreno, Plinio and van Otterlo, Martijn},
	year = {2013},
	pages = {1290--1295}
}

@inproceedings{antunes_human_2016,
	title = {From human instructions to robot actions: {Formulation} of goals, affordances and probabilistic planning},
	shorttitle = {From human instructions to robot actions},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7487757},
	urldate = {2016-11-23TZ},
	booktitle = {2016 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	publisher = {IEEE},
	author = {Antunes, Alexandre and Jamone, Lorenzo and Saponaro, Giovanni and Bernardino, Alexandre and Ventura, Rodrigo},
	year = {2016},
	pages = {5449--5454}
}

@inproceedings{nguyen_detecting_2016,
	title = {Detecting {Object} {Affordances} with {Convolutional} {Neural} {Networks}},
	url = {http://dkanou.github.io/publ/P9__Nguyen_Kanoulas_Caldwell_Tsagarakis__2016__Detecting_Object_Affordances_with_Convolutional_Neural_Networks.pdf},
	urldate = {2016-11-23TZ},
	booktitle = {{IEEE}/{RSJ} {Int}. {Conf}. on {Intelligent} {Robots} and {Systems}},
	author = {Nguyen, Anh and Kanoulas, Dimitrios and Caldwell, Darwin G. and Tsagarakis, Nikos G.},
	year = {2016}
}

@inproceedings{chavez-garcia_discovering_2016,
	title = {Discovering and {Manipulating} {Affordances}},
	url = {https://hal.archives-ouvertes.fr/hal-01391427/},
	urldate = {2016-11-23TZ},
	booktitle = {International {Symposium} on {Experimental} {Robotics} ({ISER} 2016)},
	author = {Chavez-Garcia, Omar and Andries, Mihai and Luce-Vayrac, Pierre and Chatila, Raja},
	year = {2016}
}

@article{sarathy_beyond_nodate,
	title = {Beyond {Grasping}-{Perceiving} {Affordances} {Across} {Various} {Stages} of {Cognitive} {Development}},
	volume = {12},
	url = {https://hrilab.tufts.edu/publications/sarathyscheutz2016icdl.pdf},
	urldate = {2016-11-23TZ},
	journal = {framework},
	author = {Sarathy, Vasanth and Scheutz, Matthias},
	pages = {13}
}

@inproceedings{ugur_bootstrapping_2014,
	title = {Bootstrapping paired-object affordance learning with learned single-affordance features},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6983026},
	urldate = {2016-11-23TZ},
	booktitle = {4th {International} {Conference} on {Development} and {Learning} and on {Epigenetic} {Robotics}},
	publisher = {IEEE},
	author = {Ugur, Emre and Szedmak, Sandor and Piater, Justus},
	year = {2014},
	pages = {476--481}
}

@inproceedings{ugur_bottom-up_2015,
	title = {Bottom-up learning of object categories, action effects and logical rules: {From} continuous manipulative exploration to symbolic planning},
	shorttitle = {Bottom-up learning of object categories, action effects and logical rules},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7139553},
	urldate = {2016-11-23TZ},
	booktitle = {2015 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	publisher = {IEEE},
	author = {Ugur, Emre and Piater, Justus},
	year = {2015},
	pages = {2627--2633}
}

@misc{noauthor_notitle_nodate,
	url = {https://www.cs.princeton.edu/courses/archive/fall11/cos597C/lectures/variational-inference-i.pdf},
	urldate = {2016-11-21TZ}
}

@article{sun_learning_2010,
	title = {Learning visual object categories for robot affordance prediction},
	volume = {29},
	url = {http://ijr.sagepub.com/content/29/2-3/174.short},
	number = {2-3},
	urldate = {2016-11-18TZ},
	journal = {The International Journal of Robotics Research},
	author = {Sun, Jie and Moore, Joshua L. and Bobick, Aaron and Rehg, James M.},
	year = {2010},
	pages = {174--197}
}

@inproceedings{inamura_simulator_2010,
	title = {Simulator platform that enables social interaction simulation—{SIGVerse}: {SocioIntelliGenesis} simulator},
	shorttitle = {Simulator platform that enables social interaction simulation—{SIGVerse}},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5708327},
	urldate = {2016-11-18TZ},
	booktitle = {System {Integration} ({SII}), 2010 {IEEE}/{SICE} {International} {Symposium} on},
	publisher = {IEEE},
	author = {Inamura, Tetsunari and Shibata, Tomohiro and Sena, Hideaki and Hashimoto, Takashi and Kawai, Nobuyuki and Miyashita, Takahiro and Sakurai, Yoshiki and Shimizu, Masahiro and Otake, Mihoko and Hosoda, Koh and {others}},
	year = {2010},
	pages = {212--217}
}

@inproceedings{lan_hierarchical_2014,
	title = {A hierarchical representation for future action prediction},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-10578-9_45},
	urldate = {2016-11-17TZ},
	booktitle = {European {Conference} on {Computer} {Vision}},
	publisher = {Springer},
	author = {Lan, Tian and Chen, Tsung-Chuan and Savarese, Silvio},
	year = {2014},
	pages = {689--704}
}

@article{koppula_anticipating_2016,
	title = {Anticipating human activities using object affordances for reactive robotic response},
	volume = {38},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7102751},
	number = {1},
	urldate = {2016-11-17TZ},
	journal = {IEEE transactions on pattern analysis and machine intelligence},
	author = {Koppula, Hema S. and Saxena, Ashutosh},
	year = {2016},
	pages = {14--29}
}

@article{taniguchi_symbol_2015,
	title = {Symbol {Emergence} in {Robotics}: {A} {Survey}},
	shorttitle = {Symbol {Emergence} in {Robotics}},
	url = {http://arxiv.org/abs/1509.08973},
	urldate = {2016-11-17TZ},
	journal = {arXiv preprint arXiv:1509.08973},
	author = {Taniguchi, Tadahiro and Nagai, Takayuki and Nakamura, Tomoaki and Iwahashi, Naoto and Ogata, Tetsuya and Asoh, Hideki},
	year = {2015}
}

@article{garnelo_towards_2016,
	title = {Towards {Deep} {Symbolic} {Reinforcement} {Learning}},
	url = {https://arxiv.org/abs/1609.05518},
	urldate = {2016-11-17TZ},
	journal = {arXiv preprint arXiv:1609.05518},
	author = {Garnelo, Marta and Arulkumaran, Kai and Shanahan, Murray},
	year = {2016}
}

@book{neal_bayesian_2012,
	title = {Bayesian learning for neural networks},
	volume = {118},
	url = {https://books.google.ch/books?hl=en&lr=&id=LHHrBwAAQBAJ&oi=fnd&pg=PR3&dq=BAYESIAN+LEARNING+FOR+NEURAL+NETWORKS&ots=K3AhQS5v_a&sig=lNPjC-qCalzhlkL0L1u1dGgZ3ls},
	urldate = {2016-11-17TZ},
	publisher = {Springer Science \& Business Media},
	author = {Neal, Radford M.},
	year = {2012}
}

@article{blundell_weight_2015,
	title = {Weight uncertainty in neural networks},
	url = {http://arxiv.org/abs/1505.05424},
	urldate = {2016-11-17TZ},
	journal = {arXiv preprint arXiv:1505.05424},
	author = {Blundell, Charles and Cornebise, Julien and Kavukcuoglu, Koray and Wierstra, Daan},
	year = {2015}
}

@article{korattikara_bayesian_2015,
	title = {Bayesian dark knowledge},
	url = {http://arxiv.org/abs/1506.04416},
	urldate = {2016-11-17TZ},
	journal = {arXiv preprint arXiv:1506.04416},
	author = {Korattikara, Anoop and Rathod, Vivek and Murphy, Kevin and Welling, Max},
	year = {2015}
}

@incollection{zhang_learning_2016,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Learning from {Few} {Samples} with {Memory} {Network}},
	copyright = {©2016 Springer International Publishing AG},
	isbn = {978-3-319-46686-6 978-3-319-46687-3},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-46687-3_67},
	abstract = {Neural Networks (NN) have achieved great success in pattern recognition and machine learning. However, the success of NNs usually relies on a sufficiently large number of samples. When fed with limited data, NN’s performance may be degraded significantly. In this paper, we introduce a novel neural network called Memory Network, which can learn better from limited data. Taking advantages of the memory from previous samples, the new model could achieve remarkable performance improvement on limited data. We demonstrate the memory network in Multi-Layer Perceptron (MLP). However, it keeps straightforward to extend our idea to other neural networks, e.g., Convolutional Neural Networks (CNN). We detail the network structure, present the training algorithm, and conduct a series of experiments to validate the proposed framework. Experimental results show that our model outperforms the traditional MLP and other competitive algorithms in two real data sets.},
	language = {en},
	number = {9947},
	urldate = {2016-11-17TZ},
	booktitle = {Neural {Information} {Processing}},
	publisher = {Springer International Publishing},
	author = {Zhang, Shufei and Huang, Kaizhu},
	editor = {Hirose, Akira and Ozawa, Seiichi and Doya, Kenji and Ikeda, Kazushi and Lee, Minho and Liu, Derong},
	month = oct,
	year = {2016},
	note = {DOI: 10.1007/978-3-319-46687-3\_67},
	keywords = {Artificial Intelligence (incl. Robotics), Computation by Abstract Devices, Data Mining and Knowledge Discovery, Image Processing and Computer Vision, Memory, Multi-layer perceptron, Pattern Recognition},
	pages = {606--614}
}

@article{santoro_one-shot_2016,
	title = {One-shot {Learning} with {Memory}-{Augmented} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1605.06065},
	urldate = {2016-11-17TZ},
	journal = {arXiv preprint arXiv:1605.06065},
	author = {Santoro, Adam and Bartunov, Sergey and Botvinick, Matthew and Wierstra, Daan and Lillicrap, Timothy},
	year = {2016}
}

@inproceedings{watter_embed_2015,
	title = {Embed to control: {A} locally linear latent dynamics model for control from raw images},
	shorttitle = {Embed to control},
	url = {http://papers.nips.cc/paper/5964-embed-to-control-a-locally-linear-latent-dynamics-model-for-control-from-raw-images},
	urldate = {2016-11-17TZ},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Watter, Manuel and Springenberg, Jost and Boedecker, Joschka and Riedmiller, Martin},
	year = {2015},
	pages = {2746--2754}
}

@inproceedings{tassa_receding_2008,
	title = {Receding horizon differential dynamic programming},
	url = {http://papers.nips.cc/paper/3297-receding-horizon-differential-dynamic-programming},
	urldate = {2016-11-17TZ},
	booktitle = {Advances in neural information processing systems},
	author = {Tassa, Yuval and Erez, Tom and Smart, William D.},
	year = {2008},
	pages = {1465--1472}
}

@inproceedings{todorov_generalized_2005,
	title = {A generalized iterative {LQG} method for locally-optimal feedback control of constrained nonlinear stochastic systems},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1469949},
	urldate = {2016-11-17TZ},
	booktitle = {Proceedings of the 2005, {American} {Control} {Conference}, 2005.},
	publisher = {IEEE},
	author = {Todorov, Emanuel and Li, Weiwei},
	year = {2005},
	pages = {300--306}
}

@inproceedings{levine_variational_2013,
	title = {Variational policy search via trajectory optimization},
	url = {http://papers.nips.cc/paper/5178-variational-policy-search-via-trajectory-optimization},
	urldate = {2016-11-17TZ},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Levine, Sergey and Koltun, Vladlen},
	year = {2013},
	pages = {207--215}
}

@article{wang_towards_2016,
	title = {Towards {Bayesian} {Deep} {Learning}: {A} {Survey}},
	shorttitle = {Towards {Bayesian} {Deep} {Learning}},
	url = {http://arxiv.org/abs/1604.01662},
	urldate = {2016-11-16TZ},
	journal = {arXiv preprint arXiv:1604.01662},
	author = {Wang, Hao and Yeung, Dit-Yan},
	year = {2016}
}

@article{kiela_virtual_2016,
	title = {Virtual {Embodiment}: {A} {Scalable} {Long}-{Term} {Strategy} for {Artificial} {Intelligence} {Research}},
	shorttitle = {Virtual {Embodiment}},
	url = {https://arxiv.org/abs/1610.07432},
	urldate = {2016-11-16TZ},
	journal = {arXiv preprint arXiv:1610.07432},
	author = {Kiela, Douwe and Bulat, Luana and Vero, Anita L. and Clark, Stephen},
	year = {2016}
}

@article{lotter_unsupervised_2015,
	title = {Unsupervised {Learning} of {Visual} {Structure} using {Predictive} {Generative} {Networks}},
	url = {http://arxiv.org/abs/1511.06380},
	urldate = {2016-11-14TZ},
	journal = {arXiv preprint arXiv:1511.06380},
	author = {Lotter, William and Kreiman, Gabriel and Cox, David},
	year = {2015}
}

@article{palm_prediction_2012,
	title = {Prediction as a candidate for learning deep hierarchical models of data},
	volume = {5},
	url = {http://www2.imm.dtu.dk/pubdb/views/edoc_download.php/6284/pdf/imm6284.pdf},
	urldate = {2016-11-14TZ},
	journal = {Technical University of Denmark},
	author = {Palm, Rasmus Berg},
	year = {2012}
}

@article{ugur_staged_2015,
	title = {Staged development of robot skills: {Behavior} formation, affordance learning and imitation with motionese},
	volume = {7},
	shorttitle = {Staged development of robot skills},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7094253},
	number = {2},
	urldate = {2016-11-13TZ},
	journal = {IEEE Transactions on Autonomous Mental Development},
	author = {Ugur, Emre and Nagai, Yukie and Sahin, Erol and Oztop, Erhan},
	year = {2015},
	pages = {119--139}
}

@inproceedings{wang_visual_2015,
	title = {Visual tracking with fully convolutional networks},
	url = {http://www.cv-foundation.org/openaccess/content_iccv_2015/html/Wang_Visual_Tracking_With_ICCV_2015_paper.html},
	urldate = {2016-11-13TZ},
	booktitle = {Proceedings of the {IEEE} {International} {Conference} on {Computer} {Vision}},
	author = {Wang, Lijun and Ouyang, Wanli and Wang, Xiaogang and Lu, Huchuan},
	year = {2015},
	pages = {3119--3127}
}

@article{nguyen_socially_2014,
	title = {Socially guided intrinsic motivation for robot learning of motor skills},
	volume = {36},
	url = {http://link.springer.com/article/10.1007/s10514-013-9339-y},
	number = {3},
	urldate = {2016-11-13TZ},
	journal = {Autonomous Robots},
	author = {Nguyen, Sao Mai and Oudeyer, Pierre-Yves},
	year = {2014},
	pages = {273--294}
}

@inproceedings{ugur_emergent_2014,
	title = {Emergent structuring of interdependent affordance learning tasks},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6983028},
	urldate = {2016-11-13TZ},
	booktitle = {4th {International} {Conference} on {Development} and {Learning} and on {Epigenetic} {Robotics}},
	publisher = {IEEE},
	author = {Ugur, Emre and Piater, Justus},
	year = {2014},
	pages = {489--494}
}

@article{vondrick_anticipating_nodate,
	title = {Anticipating {Visual} {Representations} from {Unlabeled} {Video}},
	url = {http://www.csee.umbc.edu/~hpirsiav/papers/prediction_cvpr16.pdf},
	urldate = {2016-11-13TZ},
	author = {Vondrick, Carl and Pirsiavash, Hamed and Torralba, Antonio}
}

@article{tagniguchi_multimodal_2015-1,
	title = {Multimodal {Hierarchical} {Dirichlet} {Process}-based {Active} {Perception}},
	url = {https://pdfs.semanticscholar.org/3298/0a97cdab6d019299d055a685c0ffe24dd4d9.pdf},
	urldate = {2016-11-13TZ},
	journal = {arXiv preprint arXiv:1510.00331},
	author = {Tagniguchi, T. and Takano, Toshiaki and Yoshino, Ryo},
	year = {2015}
}

@inproceedings{ivaldi_perception_2012,
	title = {Perception and human interaction for developmental learning of objects and affordances},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6651528},
	urldate = {2016-11-13TZ},
	booktitle = {2012 12th {IEEE}-{RAS} {International} {Conference} on {Humanoid} {Robots} ({Humanoids} 2012)},
	publisher = {IEEE},
	author = {Ivaldi, Serena and Lyubova, Natalia and Gérardeaux-Viret, Damien and Droniou, Alain and Anzalone, Salvatore M. and Chetouani, Mohamed and Filliat, David and Sigaud, Olivier},
	year = {2012},
	pages = {248--254}
}

@inproceedings{sao_mai_nguyen_learning_2013,
	title = {Learning to recognize objects through curiositydriven manipulation with the icub humanoid robot},
	url = {http://sites.isir.upmc.fr/www/files/2013ACTI2863.pdf},
	urldate = {2016-11-13TZ},
	booktitle = {{IEEE} {International} {Conference} on {Development} and {Learning}-{Epirob}},
	author = {Sao Mai Nguyen, Serena Ivaldi and Lyubova, Natalia and Droniou, Alain and Gerardeaux-Viret, Damien and Filliat, David and Padois, Vincent and Sigaud, Olivier and Oudeyer, Pierre-Yves},
	year = {2013}
}

@article{natale_icub_nodate,
	title = {The {iCub} platform: a tool for studying intrinsically motivated learning},
	shorttitle = {The {iCub} platform},
	url = {http://www.isir.upmc.fr/files/2012COS2180.pdf},
	urldate = {2016-11-13TZ},
	author = {Natale, Lorenzo and Nori, Francesco and Metta, Giorgio and Fumagalli, Matteo and Ivaldi, Serena and Pattacini, Ugo and Randazzo, Marco and Schmitz, Alexander and Sandini, Giulio}
}

@article{oudeyer_object_2013,
	title = {Object learning through active exploration},
	url = {http://ieeexplore.ieee.org/iel7/4563672/4815436/06672014.pdf},
	urldate = {2016-11-12TZ},
	author = {Oudeyer, Olivier Sigaud},
	year = {2013},
	keywords = {\_tablet}
}
@article{noda_multimodal_2014,
	title = {Multimodal integration learning of robot behavior using deep neural networks},
	volume = {62},
	issn = {0921-8890},
	url = {http://www.sciencedirect.com/science/article/pii/S0921889014000396},
	doi = {10.1016/j.robot.2014.03.003},
	abstract = {For humans to accurately understand the world around them, multimodal integration is essential because it enhances perceptual precision and reduces ambiguity. Computational models replicating such human ability may contribute to the practical use of robots in daily human living environments; however, primarily because of scalability problems that conventional machine learning algorithms suffer from, sensory-motor information processing in robotic applications has typically been achieved via modal-dependent processes. In this paper, we propose a novel computational framework enabling the integration of sensory-motor time-series data and the self-organization of multimodal fused representations based on a deep learning approach. To evaluate our proposed model, we conducted two behavior-learning experiments utilizing a humanoid robot; the experiments consisted of object manipulation and bell-ringing tasks. From our experimental results, we show that large amounts of sensory-motor information, including raw RGB images, sound spectrums, and joint angles, are directly fused to generate higher-level multimodal representations. Further, we demonstrated that our proposed framework realizes the following three functions: (1) cross-modal memory retrieval utilizing the information complementation capability of the deep autoencoder; (2) noise-robust behavior recognition utilizing the generalization capability of multimodal features; and (3) multimodal causality acquisition and sensory-motor prediction based on the acquired causality.},
	number = {6},
	urldate = {2016-11-10TZ},
	journal = {Robotics and Autonomous Systems},
	author = {Noda, Kuniaki and Arie, Hiroaki and Suga, Yuki and Ogata, Tetsuya},
	month = jun,
	year = {2014},
	keywords = {Cross-modal memory retrieval, Deep learning, Multimodal integration, Object manipulation},
	pages = {721--736}
}

@article{langkvist_review_2014,
	title = {A review of unsupervised feature learning and deep learning for time-series modeling},
	volume = {42},
	url = {http://www.sciencedirect.com/science/article/pii/S0167865514000221},
	urldate = {2016-11-10TZ},
	journal = {Pattern Recognition Letters},
	author = {Längkvist, Martin and Karlsson, Lars and Loutfi, Amy},
	year = {2014},
	pages = {11--24}
}

@article{pfeiffer_perception_2016,
	title = {From {Perception} to {Decision}: {A} {Data}-driven {Approach} to {End}-to-end {Motion} {Planning} for {Autonomous} {Ground} {Robots}},
	shorttitle = {From {Perception} to {Decision}},
	url = {https://arxiv.org/abs/1609.07910},
	urldate = {2016-11-09TZ},
	journal = {arXiv preprint arXiv:1609.07910},
	author = {Pfeiffer, Mark and Schaeuble, Michael and Nieto, Juan and Siegwart, Roland and Cadena, Cesar},
	year = {2016}
}

@article{mordatch_combining_nodate,
	title = {Combining {Model}-{Based} {Policy} {Search} with {Online} {Model} {Learning} for {Control} of {Physical} {Humanoids}},
	url = {http://www.cs.berkeley.edu/~pabbeel/papers/2016-ICRA-darwin.pdf},
	urldate = {2016-11-09TZ},
	author = {Mordatch, Igor and Mishra, Nikhil and Eppner, Clemens and Abbeel, Pieter}
}

@article{ondruska_neural_nodate,
	title = {Neural {Robotics}-{A} {New} {Perspective} {AAAI} {Robotics} {Fellowship} 2016},
	url = {http://www.robots.ox.ac.uk/~mobile/Papers/2016AAAI_RF_ondruska.pdf},
	urldate = {2016-11-09TZ},
	author = {Ondruska, Peter}
}

@article{ondruska_deep_2016,
	title = {Deep tracking: {Seeing} beyond seeing using recurrent neural networks},
	shorttitle = {Deep tracking},
	url = {http://arxiv.org/abs/1602.00991},
	urldate = {2016-11-09TZ},
	journal = {arXiv preprint arXiv:1602.00991},
	author = {Ondruska, Peter and Posner, Ingmar},
	year = {2016}
}

@inproceedings{mirza_anticipating_2008,
	title = {Anticipating future experience using grounded sensorimotor informational relationships},
	url = {http://uhra.herts.ac.uk/handle/2299/2553},
	urldate = {2016-11-09TZ},
	booktitle = {In: {Artificial} {Life} {XI}: {Proceedings} of the {Eleventh} {International} {Conference} on the {Simulation} and {Synthesis} of {Living} {Systems}},
	publisher = {MIT Press},
	author = {Mirza, Naeem Assif and Nehaniv, Chrystopher L. and Dautenhahn, Kerstin and Te Boekhorst, René},
	year = {2008}
}

@inproceedings{kose-bagci_emergent_2008,
	title = {Emergent dynamics of turn-taking interaction in drumming games with a humanoid robot},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4600690},
	urldate = {2016-11-09TZ},
	booktitle = {{RO}-{MAN} 2008-{The} 17th {IEEE} {International} {Symposium} on {Robot} and {Human} {Interactive} {Communication}},
	publisher = {IEEE},
	author = {Kose-Bagci, Hatice and Dautenhahn, Kerstin and Nehaniv, Chrystopher L.},
	year = {2008},
	pages = {346--353}
}

@article{kose-bagci_drum-mate:_2010,
	title = {Drum-mate: interaction dynamics and gestures in human–humanoid drumming experiments},
	volume = {22},
	shorttitle = {Drum-mate},
	url = {http://www.tandfonline.com/doi/abs/10.1080/09540090903383189},
	number = {2},
	urldate = {2016-11-09TZ},
	journal = {Connection Science},
	author = {Kose-Bagci, Hatice and Dautenhahn, Kerstin and Syrdal, Dag S. and Nehaniv, Chrystopher L.},
	year = {2010},
	pages = {103--134}
}

@inproceedings{kozima_robot_2001,
	title = {A robot that learns to communicate with human caregivers},
	url = {http://www.lucs.lu.se/LUCS/085/Kozima.pdf},
	urldate = {2016-11-09TZ},
	booktitle = {Proceedings of the {First} {International} {Workshop} on {Epigenetic} {Robotics}},
	author = {Kozima, Hideki and Yano, Hiroyuki},
	year = {2001},
	pages = {47--52}
}

@inproceedings{thomaz_transparency_2006,
	title = {Transparency and socially guided machine learning},
	url = {http://www.cc.gatech.edu/~athomaz/papers/ThomazBreazeal-ICDL06.pdf},
	urldate = {2016-11-09TZ},
	booktitle = {5th {Intl}. {Conf}. on {Development} and {Learning} ({ICDL})},
	author = {Thomaz, Andrea L. and Breazeal, Cynthia},
	year = {2006}
}

@article{macglashan_convergent_nodate,
	title = {Convergent {Actor} {Critic} by {Humans}},
	url = {http://irll.eecs.wsu.edu/wp-content/papercite-data/pdf/2016iros-hrc-macglashan.pdf},
	urldate = {2016-11-09TZ},
	author = {MacGlashan, James and Littman, Michael L. and Roberts, David L. and Loftin, Robert and Peng, Bei and Taylor, Matthew E.}
}

@article{schillaci_exploration_2016,
	title = {Exploration {Behaviors}, {Body} {Representations}, and {Simulation} {Processes} for the {Development} of {Cognition} in {Artificial} {Agents}},
	url = {http://journal.frontiersin.org/article/10.3389/frobt.2016.00039/full},
	doi = {10.3389/frobt.2016.00039},
	abstract = {Sensorimotor control and learning are fundamental prerequisites for cognitive development in humans and animals. Evidence from behavioral sciences and neuroscience suggests that motor and brain development are strongly intertwined with the experiential process of exploration, where internal body representations are formed and maintained over time. In order to guide our movements, our brain must hold an internal model of our body and constantly monitor its configuration state. How can sensorimotor control enable the development of more complex cognitive and motor capabilities? Although a clear answer has still not been found for this question, several studies suggest that processes of mental simulation of action–perception loops are likely to be executed in our brain and are dependent on internal body representations. Therefore, the capability to re-enact sensorimotor experience might represent a key mechanism behind the implementation of higher cognitive capabilities, such as behavior recognition, arbitration and imitation, sense of agency, and self–other distinction. This work is mainly addressed to researchers in autonomous motor and mental development for artificial agents. In particular, it aims at gathering the latest developments in the studies on exploration behaviors, internal body representations, and processes of sensorimotor simulations. Relevant studies in human and animal sciences are discussed and a parallel to similar investigations in robotics is presented.},
	urldate = {2016-11-09TZ},
	journal = {Humanoid Robotics},
	author = {Schillaci, Guido and Hafner, Verena V. and Lara, Bruno},
	year = {2016},
	keywords = {body representations, developmental robotics, exploration behaviors, internal models, sensorimotor learning, sensorimotor simulations},
	pages = {39}
}

@incollection{hoffmann_minimally_2014,
	title = {Minimally cognitive robotics: body schema, forward models, and sensorimotor contingencies in a quadruped machine},
	shorttitle = {Minimally cognitive robotics},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-05107-9_15},
	urldate = {2016-11-09TZ},
	booktitle = {Contemporary {Sensorimotor} {Theory}},
	publisher = {Springer},
	author = {Hoffmann, Matej},
	year = {2014},
	pages = {209--233}
}

@misc{noauthor_evolving_nodate,
	title = {Evolving {AI} {Lab} - {University} of {Wyoming}},
	url = {http://www.evolvingai.org/yosinski-clune-hidalgo-nguyen-2011-evolving-robot-gaits-hardware},
	abstract = {The Evolving AI Lab at the University of Wyoming focuses on evolving artificially intelligent robots. Please visit EvolvingAI.org to watch videos of, and read about, our work.},
	urldate = {2016-11-07TZ}
}

@inproceedings{moulin-frier_explauto:_2014,
	title = {Explauto: an open-source {Python} library to study autonomous exploration in developmental robotics},
	shorttitle = {Explauto},
	url = {https://hal.inria.fr/hal-01061708/document},
	abstract = {We present an open-source Python library, called Explauto, providing a unified API to design and compare various exploration strategies driving various sensorimotor learning algorithms in various simulated or robotics systems. Explauto aims at being collaborative and pedagogic, providing a platform to developmental roboticists where they can publish and compare their algorithmic contributions related to autonomous exploration and learning, as well as a platform for teaching and scientific diffusion. The library is available at this address: https://github.com/flowersteam/explauto},
	language = {en},
	urldate = {2016-11-07TZ},
	author = {Moulin-Frier, Clément and Rouanet, Pierre and Oudeyer, Pierre-Yves},
	month = oct,
	year = {2014}
}

@article{marblestone_toward_2016,
	title = {Toward an {Integration} of {Deep} {Learning} and {Neuroscience}},
	url = {http://journal.frontiersin.org/article/10.3389/fncom.2016.00094/full},
	doi = {10.3389/fncom.2016.00094},
	abstract = {Neuroscience has focused on the detailed implementation of computation, studying neural codes, dynamics and circuits. In machine learning, however, artificial neural networks tend to eschew precisely designed codes, dynamics or circuits in favor of brute force optimization of a cost function, often using simple and relatively uniform initial architectures. Two recent developments have emerged within machine learning that create an opportunity to connect these seemingly divergent perspectives. First, structured architectures are used, including dedicated systems for attention, recursion and various forms of short- and long-term memory storage. Second, cost functions and training procedures have become more complex and are varied across layers and over time. Here we think about the brain in terms of these ideas. We hypothesize that (1) the brain optimizes cost functions, (2) the cost functions are diverse and differ across brain locations and over development, and (3) optimization operates within a pre-structured architecture matched to the computational problems posed by behavior. In support of these hypotheses, we argue that a range of implementations of credit assignment through multiple layers of neurons are compatible with our current knowledge of neural circuitry, and that the brain's specialized systems can be interpreted as enabling efficient optimization for specific problem classes. Such a heterogeneously optimized system, enabled by a series of interacting cost functions, serves to make learning data-efficient and precisely targeted to the needs of the organism. We suggest directions by which neuroscience could seek to refine and test these hypotheses.},
	urldate = {2016-11-07TZ},
	journal = {Frontiers in Computational Neuroscience},
	author = {Marblestone, Adam H. and Wayne, Greg and Kording, Konrad P.},
	year = {2016},
	keywords = {Neural networks, cognitive architecture, cost functions, neuroscience},
	pages = {94}
}

@article{nehaniv_interaction_nodate,
	title = {Interaction and {Experience} in {Enactive} {Intelligence} and {Humanoid} {Robotics}},
	url = {https://www.researchgate.net/profile/Chrystopher_Nehaniv/publication/236236674_Interaction_and_Experience_in_Enactive_Intelligence_and_Humanoid_Robotics/links/556986af08aec22683033d95.pdf},
	urldate = {2016-11-07TZ},
	author = {Nehaniv, Chrystopher L. and Förster, Frank and Saunders, Joe and Broz, Frank and Antonova, Elena and Köse, Hatice and Lyon, Caroline and Lehmann, Hagen and Sato, Yo and Dautenhahn, Kerstin}
}

@article{schmidhuber_learning_2015,
	title = {On learning to think: {Algorithmic} information theory for novel combinations of reinforcement learning controllers and recurrent neural world models},
	shorttitle = {On learning to think},
	url = {http://arxiv.org/abs/1511.09249},
	urldate = {2016-11-07TZ},
	journal = {arXiv preprint arXiv:1511.09249},
	author = {Schmidhuber, Juergen},
	year = {2015}
}

@article{rezende_one-shot_2016,
	title = {One-{Shot} {Generalization} in {Deep} {Generative} {Models}},
	url = {http://arxiv.org/abs/1603.05106},
	urldate = {2016-11-07TZ},
	journal = {arXiv preprint arXiv:1603.05106},
	author = {Rezende, Danilo Jimenez and Mohamed, Shakir and Danihelka, Ivo and Gregor, Karol and Wierstra, Daan},
	year = {2016}
}

@article{grossberg_how_2010,
	title = {How do children learn to follow gaze, share joint attention, imitate their teachers, and use tools during social interactions?},
	volume = {23},
	url = {http://www.sciencedirect.com/science/article/pii/S0893608010001504},
	number = {8},
	urldate = {2016-11-07TZ},
	journal = {Neural Networks},
	author = {Grossberg, Stephen and Vladusich, Tony},
	year = {2010},
	pages = {940--965}
}

@inproceedings{yu_investigating_2010,
	title = {Investigating multimodal real-time patterns of joint attention in an hri word learning task},
	url = {http://dl.acm.org/citation.cfm?id=1734561},
	urldate = {2016-11-07TZ},
	booktitle = {Proceedings of the 5th {ACM}/{IEEE} international conference on {Human}-robot interaction},
	publisher = {IEEE Press},
	author = {Yu, Chen and Scheutz, Matthias and Schermerhorn, Paul},
	year = {2010},
	pages = {309--316}
}

@article{begum_visual_2011,
	title = {Visual attention for robotic cognition: a survey},
	volume = {3},
	shorttitle = {Visual attention for robotic cognition},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5659891},
	number = {1},
	urldate = {2016-11-07TZ},
	journal = {IEEE Transactions on Autonomous Mental Development},
	author = {Begum, Momotaz and Karray, Fakhri},
	year = {2011},
	pages = {92--105}
}

@inproceedings{park_understanding_2010,
	title = {Understanding a child's play for robot interaction by sequencing play primitives using hidden markov models},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5509156},
	urldate = {2016-11-07TZ},
	booktitle = {Robotics and {Automation} ({ICRA}), 2010 {IEEE} {International} {Conference} on},
	publisher = {IEEE},
	author = {Park, Hae Won and Howard, Ayanna M.},
	year = {2010},
	pages = {170--177}
}

@inproceedings{maeda_learning_2014,
	title = {Learning interaction for collaborative tasks with probabilistic movement primitives},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7041413},
	urldate = {2016-11-07TZ},
	booktitle = {2014 {IEEE}-{RAS} {International} {Conference} on {Humanoid} {Robots}},
	publisher = {IEEE},
	author = {Maeda, Guilherme and Ewerton, Marco and Lioutikov, Rudolf and Amor, Heni Ben and Peters, Jan and Neumann, Gerhard},
	year = {2014},
	pages = {527--534}
}

@article{grand_synchrony_2014,
	series = {International {Conference} on {Timing} and {Time} {Perception}, 31 {March} – 3 {April} 2014, {Corfu}, {Greece}},
	title = {Synchrony {Detection} as a {Reinforcement} {Signal} for {Learning}: {Application} to {Human} {Robot} {Interaction}},
	volume = {126},
	issn = {1877-0428},
	shorttitle = {Synchrony {Detection} as a {Reinforcement} {Signal} for {Learning}},
	url = {http://www.sciencedirect.com/science/article/pii/S1877042814018709},
	doi = {10.1016/j.sbspro.2014.02.322},
	abstract = {The present study is aiming to build a synchrony-based attentional mechanism allowing to initiate and to maintain human robot interactions. Moreover, we question the importance of synchrony detection for learning and gaining new competences through the interaction. We previously proposed a synchrony-based neural model capable of giving the robot minimal abilities to select a human partner and to focus its visual attention on this preferred interactant. Here, we extend this model by using synchrony detection as a reinforcement signal for learning (during the interaction) the human partner appearance (shape) in the context of an autonomous mobile robot.},
	urldate = {2016-11-07TZ},
	journal = {Procedia - Social and Behavioral Sciences},
	author = {Grand, Caroline and Mostafaoui, Ghilès and Hasnain, Syed Khursheed and Gaussier, Philippe},
	month = mar,
	year = {2014},
	keywords = {Dynamical systems, Focus of attention, Intuitive human robot interaction, Neural networks, Partner selection, Synchrony},
	pages = {82--91}
}

@inproceedings{hiolle_using_2010,
	title = {Using the interaction rhythm as a natural reinforcement signal for social robots: a matter of belief},
	shorttitle = {Using the interaction rhythm as a natural reinforcement signal for social robots},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-17248-9_9},
	urldate = {2016-11-07TZ},
	booktitle = {International {Conference} on {Social} {Robotics}},
	publisher = {Springer},
	author = {Hiolle, Antoine and Cañamero, Lola and Andry, Pierre and Blanchard, Arnaud and Gaussier, Philippe},
	year = {2010},
	pages = {81--89}
}

@inproceedings{hasnain_synchrony_2012,
	title = {Synchrony as a tool to establish focus of attention for autonomous robots},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6385912},
	urldate = {2016-11-07TZ},
	booktitle = {2012 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	publisher = {IEEE},
	author = {Hasnain, Syed Khursheed and Gaussier, Philippe and Mostafaoui, Ghiles},
	year = {2012},
	pages = {2423--2428}
}

@article{rolf_attention_2009,
	title = {Attention via synchrony: {Making} use of multimodal cues in social learning},
	volume = {1},
	shorttitle = {Attention via synchrony},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4815438},
	number = {1},
	urldate = {2016-11-07TZ},
	journal = {IEEE Transactions on Autonomous Mental Development},
	author = {Rolf, Matthias and Hanheide, Marc and Rohlfing, Katharina J.},
	year = {2009},
	pages = {55--67}
}

@article{hasnain_synchrony-based_2012,
	title = {A synchrony-based perspective for partner selection and attentional mechanism in human-robot interaction},
	volume = {3},
	url = {http://www.degruyter.com/view/j/pjbr.2012.3.issue-3/s13230-013-0111-y/s13230-013-0111-y.xml},
	number = {3},
	urldate = {2016-11-07TZ},
	journal = {Paladyn, Journal of Behavioral Robotics},
	author = {Hasnain, Syed Khursheed and Mostafaoui, Ghiles and Gaussier, Philippe},
	year = {2012},
	pages = {156--171}
}

@inproceedings{lohan_contingency_2011,
	title = {Contingency allows the robot to spot the tutor and to learn from interaction},
	volume = {2},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6037341},
	urldate = {2016-11-07TZ},
	booktitle = {2011 {IEEE} {International} {Conference} on {Development} and {Learning} ({ICDL})},
	publisher = {IEEE},
	author = {Lohan, Katrin S. and Pitsch, Karola and Rohlfing, Katharina J. and Fischer, Kerstin and Saunders, Joe and Lehmann, Hagen and Nehaniv, Chrystopher and Wrede, Britta},
	year = {2011},
	pages = {1--8}
}

@article{andry_using_2011,
	title = {Using the rhythm of nonverbal human–robot interaction as a signal for learning},
	volume = {3},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5664771},
	number = {1},
	urldate = {2016-11-07TZ},
	journal = {IEEE Transactions on Autonomous Mental Development},
	author = {Andry, Pierre and Blanchard, Arnaud and Gaussier, Philippe},
	year = {2011},
	pages = {30--42}
}

@article{stolk_conceptual_2016,
	title = {Conceptual {Alignment}: {How} {Brains} {Achieve} {Mutual} {Understanding}},
	volume = {20},
	issn = {1364-6613},
	shorttitle = {Conceptual {Alignment}},
	url = {http://www.sciencedirect.com/science/article/pii/S1364661315002867},
	doi = {10.1016/j.tics.2015.11.007},
	abstract = {We share our thoughts with other minds, but we do not understand how. Having a common language certainly helps, but infants’ and tourists’ communicative success clearly illustrates that sharing thoughts does not require signals with a pre-assigned meaning. In fact, human communicators jointly build a fleeting conceptual space in which signals are a means to seek and provide evidence for mutual understanding. Recent work has started to capture the neural mechanisms supporting those fleeting conceptual alignments. The evidence suggests that communicators and addressees achieve mutual understanding by using the same computational procedures, implemented in the same neuronal substrate, and operating over temporal scales independent from the signals’ occurrences.},
	number = {3},
	urldate = {2016-11-07TZ},
	journal = {Trends in Cognitive Sciences},
	author = {Stolk, Arjen and Verhagen, Lennart and Toni, Ivan},
	month = mar,
	year = {2016},
	pages = {180--191}
}

@article{wong_towards_2016,
	title = {Towards {Lifelong} {Self}-{Supervision}: {A} {Deep} {Learning} {Direction} for {Robotics}},
	shorttitle = {Towards {Lifelong} {Self}-{Supervision}},
	url = {https://arxiv.org/abs/1611.00201},
	urldate = {2016-11-07TZ},
	journal = {arXiv preprint arXiv:1611.00201},
	author = {Wong, Jay M.},
	year = {2016}
}

@article{yamada_dynamical_2016,
	title = {Dynamical {Integration} of {Language} and {Behavior} in a {Recurrent} {Neural} {Network} for {Human}–{Robot} {Interaction}},
	volume = {10},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4946379/},
	urldate = {2016-11-07TZ},
	journal = {Frontiers in Neurorobotics},
	author = {Yamada, Tatsuro and Murata, Shingo and Arie, Hiroaki and Ogata, Tetsuya},
	year = {2016}
}

@inproceedings{sequeira_discovering_2016,
	title = {Discovering social interaction strategies for robots from restricted-perception {Wizard}-of-{Oz} studies},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7451752},
	urldate = {2016-11-07TZ},
	booktitle = {2016 11th {ACM}/{IEEE} {International} {Conference} on {Human}-{Robot} {Interaction} ({HRI})},
	publisher = {IEEE},
	author = {Sequeira, Pedro and Ribeiro, Tiago and Di Tullio, Eugenio and Petisca, Sofia and Melo, Francisco S. and Castellano, Ginevra and Paiva, Ana and {others}},
	year = {2016},
	pages = {197--204}
}
@article{pinto_curious_2016,
	title = {The {Curious} {Robot}: {Learning} {Visual} {Representations} via {Physical} {Interactions}},
	shorttitle = {The {Curious} {Robot}},
	url = {http://arxiv.org/abs/1604.01360},
	urldate = {2016-11-07TZ},
	journal = {arXiv preprint arXiv:1604.01360},
	author = {Pinto, Lerrel and Gandhi, Dhiraj and Han, Yuanfeng and Park, Yong-Lae and Gupta, Abhinav},
	year = {2016}
}

@article{vallverdu_emotional_2016,
	title = {Emotional affordances for human–robot interaction},
	url = {http://adb.sagepub.com/content/early/2016/10/09/1059712316668238.abstract},
	urldate = {2016-11-07TZ},
	journal = {Adaptive Behavior},
	author = {Vallverdú, Jordi and Trovato, Gabriele},
	year = {2016},
	pages = {1059712316668238}
}

@article{chao_timed_2016,
	title = {Timed {Petri} nets for fluent turn-taking over multimodal interaction resources in human-robot collaboration},
	issn = {0278-3649, 1741-3176},
	url = {http://ijr.sagepub.com/content/early/2016/03/09/0278364915627291},
	doi = {10.1177/0278364915627291},
	abstract = {The goal of this work is to develop computational models of social intelligence that enable robots to work side by side with humans, solving problems and achieving task goals through dialogue and collaborative manipulation. A defining problem of collaborative behavior in an embodied setting is the manner in which multiple agents make use of shared resources. In a situated dialogue, these resources include physical bottlenecks such as objects or spatial regions, and cognitive bottlenecks such as the speaking floor. For a robot to function as an effective collaborative partner with a human, it must be able to seize and yield such resources appropriately according to social expectations. We describe a general framework that uses timed Petri nets for the modeling and execution of robot speech, gaze, gesture, and manipulation for collaboration. The system dynamically monitors resource requirements and availability to control real-time turn-taking decisions over resources that are shared with humans, reasoning about different resource types independently. We evaluate our approach with an experiment in which our robot Simon performs a collaborative assembly task with 26 different human partners, showing that the multimodal reciprocal approach results in superior task performance, fluency, and balance of control.},
	language = {en},
	urldate = {2016-11-07TZ},
	journal = {The International Journal of Robotics Research},
	author = {Chao, Crystal and Thomaz, Andrea},
	month = mar,
	year = {2016},
	keywords = {Turn-taking, behavior architecture, collaborative discourse, collaborative manipulation, human-robot collaboration, human-robot interaction, joint action, situated dialogue, social interaction, timed Petri nets},
	pages = {0278364915627291}
}

@inproceedings{kim_human-robot_2015,
	title = {Human-{Robot} {Interaction} using {Intention} {Recognition}},
	url = {http://dl.acm.org/citation.cfm?id=2815002},
	urldate = {2016-11-07TZ},
	booktitle = {Proceedings of the 3rd {International} {Conference} on {Human}-{Agent} {Interaction}},
	publisher = {ACM},
	author = {Kim, Sangwook and Yu, Zhibin and Kim, Jonghong and Ojha, Amitash and Lee, Minho},
	year = {2015},
	pages = {299--302}
}

@article{wulfmeier_deep_2015,
	title = {Deep {Inverse} {Reinforcement} {Learning}},
	url = {http://arxiv.org/abs/1507.04888},
	urldate = {2016-11-07TZ},
	journal = {arXiv preprint arXiv:1507.04888},
	author = {Wulfmeier, Markus and Ondruska, Peter and Posner, Ingmar},
	year = {2015}
}

@article{wulfmeier_maximum_2015,
	title = {Maximum {Entropy} {Deep} {Inverse} {Reinforcement} {Learning}},
	url = {https://pdfs.semanticscholar.org/270a/f733bcf18d9c14230bcffc77d6ae57e2667d.pdf},
	urldate = {2016-11-07TZ},
	journal = {arXiv preprint arXiv:1507.04888},
	author = {Wulfmeier, Markus and Ondruska, Peter and Posner, Ingmar},
	year = {2015}
}

@article{ho_generative_2016,
	title = {Generative adversarial imitation learning},
	url = {https://arxiv.org/abs/1606.03476},
	urldate = {2016-11-07TZ},
	journal = {arXiv preprint arXiv:1606.03476},
	author = {Ho, Jonathan and Ermon, Stefano},
	year = {2016}
}

@inproceedings{nicolescu_natural_2003,
	title = {Natural methods for robot task learning: {Instructive} demonstrations, generalization and practice},
	shorttitle = {Natural methods for robot task learning},
	url = {http://dl.acm.org/citation.cfm?id=860614},
	urldate = {2016-11-03TZ},
	booktitle = {Proceedings of the second international joint conference on {Autonomous} agents and multiagent systems},
	publisher = {ACM},
	author = {Nicolescu, Monica N. and Mataric, Maja J.},
	year = {2003},
	pages = {241--248}
}

@article{lemme_kinesthetic_nodate,
	title = {Kinesthetic teaching of visuomotor coordination for pointing by the humanoid robot {iCub}},
	url = {https://www.researchgate.net/profile/Guilherme_Barreto2/publication/236246884_Kinesthetic_teaching_of_visuomotor_coordination_for_pointing_by_the_humanoid_robot_iCub/links/00463517581934eb64000000.pdf},
	urldate = {2016-11-03TZ},
	author = {Lemme, Andre and Freire, Ananda and Barreto, Guilherme and Steil, Jochen}
}

@article{pfau_connecting_2016,
	title = {Connecting {Generative} {Adversarial} {Networks} and {Actor}-{Critic} {Methods}},
	url = {https://arxiv.org/abs/1610.01945},
	urldate = {2016-11-02TZ},
	journal = {arXiv preprint arXiv:1610.01945},
	author = {Pfau, David and Vinyals, Oriol},
	year = {2016}
}

@article{lever_deterministic_2014,
	title = {Deterministic policy gradient algorithms},
	url = {http://www.jmlr.org/proceedings/papers/v32/silver14.pdf},
	urldate = {2016-11-02TZ},
	author = {Lever, Guy},
	year = {2014}
}

@inproceedings{hasselt_double_2010,
	title = {Double {Q}-learning},
	url = {http://papers.nips.cc/paper/3964-double-q-learning},
	urldate = {2016-11-02TZ},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Hasselt, Hado V.},
	year = {2010},
	pages = {2613--2621}
}

@article{najar_training_nodate,
	title = {Training a robot with evaluative feedback and unlabeled guidance signals},
	url = {http://www.isir.upmc.fr/files/2016ACTI3709.pdf},
	urldate = {2016-11-02TZ},
	author = {Najar, Anis and Sigaud, Olivier and Chetouani, Mohamed}
}

@inproceedings{najar_socially_2015,
	title = {Socially guided {XCS}: using teaching signals to boost learning},
	shorttitle = {Socially guided {XCS}},
	url = {http://dl.acm.org/citation.cfm?id=2768452},
	urldate = {2016-11-02TZ},
	booktitle = {Proceedings of the {Companion} {Publication} of the 2015 {Annual} {Conference} on {Genetic} and {Evolutionary} {Computation}},
	publisher = {ACM},
	author = {Najar, Anis and Sigaud, Olivier and Chetouani, Mohamed},
	year = {2015},
	pages = {1021--1028}
}

@inproceedings{najar_social-task_2015,
	title = {Social-{Task} {Learning} for {HRI}},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-25554-5_47},
	urldate = {2016-11-02TZ},
	booktitle = {International {Conference} on {Social} {Robotics}},
	publisher = {Springer},
	author = {Najar, Anis and Sigaud, Olivier and Chetouani, Mohamed},
	year = {2015},
	pages = {472--481}
}

@inproceedings{levine_learning_2014,
	title = {Learning neural network policies with guided policy search under unknown dynamics},
	url = {http://papers.nips.cc/paper/5444-learning-neural-network-policies-with-guided-policy-search-under-unknown-dynamics},
	urldate = {2016-10-31TZ},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Levine, Sergey and Abbeel, Pieter},
	year = {2014},
	pages = {1071--1079}
}

@article{lillicrap_continuous_2015,
	title = {Continuous control with deep reinforcement learning},
	url = {http://arxiv.org/abs/1509.02971},
	urldate = {2016-10-31TZ},
	journal = {arXiv preprint arXiv:1509.02971},
	author = {Lillicrap, Timothy P. and Hunt, Jonathan J. and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
	year = {2015}
}

@article{stulp_robot_2013,
	title = {Robot skill learning: {From} reinforcement learning to evolution strategies},
	volume = {4},
	shorttitle = {Robot skill learning},
	url = {http://www.degruyter.com/view/j/pjbr.2013.4.issue-1/pjbr-2013-0003/pjbr-2013-0003.xml},
	number = {1},
	urldate = {2016-10-31TZ},
	journal = {Paladyn, Journal of Behavioral Robotics},
	author = {Stulp, Freek and Sigaud, Olivier},
	year = {2013},
	pages = {49--61}
}

@article{pasa_neural_2015,
	title = {Neural {Networks} for {Sequential} {Data}: a {Pre}-training {Approach} based on {Hidden} {Markov} {Models}},
	volume = {169},
	shorttitle = {Neural {Networks} for {Sequential} {Data}},
	url = {http://www.sciencedirect.com/science/article/pii/S0925231215003689},
	urldate = {2016-10-31TZ},
	journal = {Neurocomputing},
	author = {Pasa, Luca and Testolin, Alberto and Sperduti, Alessandro},
	year = {2015},
	pages = {323--333}
}

@article{clark_whatever_2013,
	title = {Whatever next? {Predictive} brains, situated agents, and the future of cognitive science},
	volume = {36},
	shorttitle = {Whatever next?},
	url = {http://journals.cambridge.org/abstract_S0140525X12000477},
	number = {03},
	urldate = {2016-10-31TZ},
	journal = {Behavioral and Brain Sciences},
	author = {Clark, Andy},
	year = {2013},
	pages = {181--204}
}

@article{pezzulo_actions_nodate,
	title = {From {Actions} to {Goals} and {Vice}-versa: {Theoretical} {Analysis} and {Models} of the {Ideomotor} {Principle} and {TOTE}},
	shorttitle = {From {Actions} to {Goals} and {Vice}-versa},
	url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.330.6627&rep=rep1&type=pdf},
	urldate = {2016-10-31TZ},
	author = {Pezzulo, Giovanni and Baldassarre, Gianluca and Butz, Martin V. and Castelfranchi, Cristiano and Hoffmann, Joachim}
}

@inproceedings{memisevic_gated_2010,
	title = {Gated softmax classification},
	url = {http://papers.nips.cc/paper/3895-gated-softmax-classification},
	urldate = {2016-10-31TZ},
	booktitle = {Advances in neural information processing systems},
	author = {Memisevic, Roland and Zach, Christopher and Pollefeys, Marc and Hinton, Geoffrey E.},
	year = {2010},
	pages = {1603--1611}
}

@inproceedings{broz_learning_2009,
	title = {Learning behavior for a social interaction game with a childlike humanoid robot},
	url = {http://robotcub.org/misc/papers/09_Broz_etal.pdf},
	urldate = {2016-10-31TZ},
	booktitle = {Social {Learning} in {Interactive} {Scenarios} {Workshop}, {Humanoids}},
	author = {Broz, Frank and Kose-Bagci, Hatice and Nehaniv, Chrystopher L. and Dautenhahn, Kerstin},
	year = {2009}
}

@article{asada_cognitive_2009,
	title = {Cognitive developmental robotics: a survey},
	volume = {1},
	shorttitle = {Cognitive developmental robotics},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4895715},
	number = {1},
	urldate = {2016-10-31TZ},
	journal = {IEEE Transactions on Autonomous Mental Development},
	author = {Asada, Minoru and Hosoda, Koh and Kuniyoshi, Yasuo and Ishiguro, Hiroshi and Inui, Toshio and Yoshikawa, Yuichiro and Ogino, Masaki and Yoshida, Chisato},
	year = {2009},
	pages = {12--34}
}

@inproceedings{peltason_mixed-initiative_2009,
	title = {Mixed-initiative in human augmented mapping},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5152683},
	urldate = {2016-10-31TZ},
	booktitle = {Robotics and {Automation}, 2009. {ICRA}'09. {IEEE} {International} {Conference} on},
	publisher = {IEEE},
	author = {Peltason, Julia and Siepmann, Frederic HK and Spexard, Thorsten P. and Wrede, Britta and Hanheide, Marc and Topp, Elin A.},
	year = {2009},
	pages = {2146--2153}
}

@inproceedings{lutkebohle_curious_2009,
	title = {The curious robot-structuring interactive robot learning},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5152521},
	urldate = {2016-10-31TZ},
	booktitle = {Robotics and {Automation}, 2009. {ICRA}'09. {IEEE} {International} {Conference} on},
	publisher = {IEEE},
	author = {Lutkebohle, Ingo and Peltason, Julia and Schillingmann, Lars and Wrede, Britta and Wachsmuth, Sven and Elbrechter, Christof and Haschke, Robert},
	year = {2009},
	pages = {4156--4162}
}

@article{kording_bayesian_2004,
	title = {Bayesian integration in sensorimotor learning},
	volume = {427},
	url = {http://www.nature.com/nature/journal/v427/n6971/abs/nature02169.html},
	number = {6971},
	urldate = {2016-10-31TZ},
	journal = {Nature},
	author = {Körding, Konrad P. and Wolpert, Daniel M.},
	year = {2004},
	pages = {244--247}
}

@incollection{toussaint_bayesian_2010,
	title = {A bayesian view on motor control and planning},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-05181-4_11},
	urldate = {2016-10-31TZ},
	booktitle = {From {Motor} {Learning} to {Interaction} {Learning} in {Robots}},
	publisher = {Springer},
	author = {Toussaint, Marc and Goerick, Christian},
	year = {2010},
	pages = {227--252}
}

@inproceedings{ng_algorithms_2000,
	title = {Algorithms for inverse reinforcement learning.},
	url = {http://ai.stanford.edu/~ang/papers/icml00-irl.pdf},
	urldate = {2016-10-31TZ},
	booktitle = {Icml},
	author = {Ng, Andrew Y. and Russell, Stuart J. and {others}},
	year = {2000},
	pages = {663--670}
}

@article{wolpert_unifying_2003,
	title = {A unifying computational framework for motor control and social interaction},
	volume = {358},
	url = {http://rstb.royalsocietypublishing.org/content/358/1431/593.short},
	number = {1431},
	urldate = {2016-10-31TZ},
	journal = {Philosophical Transactions of the Royal Society of London B: Biological Sciences},
	author = {Wolpert, Daniel M. and Doya, Kenji and Kawato, Mitsuo},
	year = {2003},
	pages = {593--602}
}

@inproceedings{rolf_online_2011,
	title = {Online goal babbling for rapid bootstrapping of inverse models in high dimensions},
	volume = {2},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6037368},
	urldate = {2016-10-31TZ},
	booktitle = {2011 {IEEE} {International} {Conference} on {Development} and {Learning} ({ICDL})},
	publisher = {IEEE},
	author = {Rolf, Matthias and Steil, Jochen J. and Gienger, Michael},
	year = {2011},
	pages = {1--8}
}

@inproceedings{baranes_intrinsically_2010,
	title = {Intrinsically motivated goal exploration for active motor learning in robots: {A} case study},
	shorttitle = {Intrinsically motivated goal exploration for active motor learning in robots},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5651385},
	urldate = {2016-10-31TZ},
	booktitle = {Intelligent {Robots} and {Systems} ({IROS}), 2010 {IEEE}/{RSJ} {International} {Conference} on},
	publisher = {IEEE},
	author = {Baranes, Adrien and Oudeyer, Pierre-Yves},
	year = {2010},
	pages = {1766--1773}
}

@article{baranes_active_2013,
	title = {Active learning of inverse models with intrinsically motivated goal exploration in robots},
	volume = {61},
	url = {http://www.sciencedirect.com/science/article/pii/S0921889012000644},
	number = {1},
	urldate = {2016-10-31TZ},
	journal = {Robotics and Autonomous Systems},
	author = {Baranes, Adrien and Oudeyer, Pierre-Yves},
	year = {2013},
	pages = {49--73}
}

@book{yamashita_emergence_2008,
	title = {Emergence of {Functional} {Hierarchy} in a {Multiple} {Timescale} {Neural} {Network} {Model}: {A} {Humanoid} {Robot} {Experiment}},
	shorttitle = {Emergence of {Functional} {Hierarchy} in a {Multiple} {Timescale} {Neural} {Network} {Model}},
	url = {http://neurorobot.kaist.ac.kr/publications/pdf_files/PLoSCB_2008_corrected.pdf},
	urldate = {2016-10-31TZ},
	publisher = {PLoS},
	author = {Yamashita, Y. and Tani, J. and Sporns, Olaf},
	year = {2008}
}

@inproceedings{calinon_framework_2008,
	title = {A framework integrating statistical and social cues to teach a humanoid robot new skills},
	url = {http://infoscience.epfl.ch/record/117850},
	urldate = {2016-10-31TZ},
	booktitle = {Proceedings of the {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA}), {Workshop} on {Social} {Interaction} with {Intelligent} {Indoor} {Robots}},
	author = {Calinon, Sylvain and Billard, Aude},
	year = {2008}
}
@inproceedings{chernova_confidence-based_2007,
	title = {Confidence-based policy learning from demonstration using gaussian mixture models},
	url = {http://dl.acm.org/citation.cfm?id=1329407},
	urldate = {2016-10-31TZ},
	booktitle = {Proceedings of the 6th international joint conference on {Autonomous} agents and multiagent systems},
	publisher = {ACM},
	author = {Chernova, Sonia and Veloso, Manuela},
	year = {2007},
	pages = {233}
}

@inproceedings{niculescu-mizil_inductive_2007,
	title = {Inductive {Transfer} for {Bayesian} {Network} {Structure} {Learning}.},
	url = {http://www.jmlr.org/proceedings/papers/v2/niculescu-mizil07a/niculescu-mizil07a.pdf},
	urldate = {2016-10-31TZ},
	booktitle = {{AISTATS}},
	author = {Niculescu-Mizil, Alexandru and Caruana, Rich},
	year = {2007},
	pages = {339--346}
}

@phdthesis{murphy_dynamic_2002,
	title = {Dynamic bayesian networks: representation, inference and learning},
	shorttitle = {Dynamic bayesian networks},
	url = {http://cs.ubc.ca/~murphyk/Thesis/thesis.pdf},
	urldate = {2016-10-31TZ},
	school = {University of California, Berkeley},
	author = {Murphy, Kevin Patrick},
	year = {2002}
}

@incollection{ghahramani_learning_1998,
	title = {Learning dynamic {Bayesian} networks},
	url = {http://link.springer.com/chapter/10.1007/BFb0053999},
	urldate = {2016-10-31TZ},
	booktitle = {Adaptive processing of sequences and data structures},
	publisher = {Springer},
	author = {Ghahramani, Zoubin},
	year = {1998},
	pages = {168--197}
}

@article{tenenbaum_theory-based_2006,
	title = {Theory-based {Bayesian} models of inductive learning and reasoning},
	volume = {10},
	url = {http://www.sciencedirect.com/science/article/pii/S1364661306001343},
	number = {7},
	urldate = {2016-10-31TZ},
	journal = {Trends in cognitive sciences},
	author = {Tenenbaum, Joshua B. and Griffiths, Thomas L. and Kemp, Charles},
	year = {2006},
	pages = {309--318}
}

@article{jordan_learning_2004,
	title = {Learning in graphical models},
	volume = {19},
	abstract = {Statistical applications in fields such as bioinformatics, information retrieval, speech processing, image processing and communications often involve large-scale models in which thousands or millions of random variables are linked in complex ways. Graphical models provide a general methodology for approaching these problems, and indeed many of the models developed by researchers in these applied fields are instances of the general graphical model formalism. We review some of the basic ideas underlying graphical models, including the algorithmic ideas that allow graphical models to be deployed in large-scale data analysis problems. We also present examples of graphical models in bioinformatics, error-control coding and language processing.},
	number = {1},
	journal = {Statistical Science},
	author = {Jordan, Michael I.},
	year = {2004},
	pages = {140--155}
}

@misc{noauthor_notitle_nodate,
	url = {http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=BA7F5D9528CCCE140FBF90C8C7616180?doi=10.1.1.114.4996&rep=rep1&type=pdf},
	urldate = {2016-10-31TZ}
}

@article{argall_survey_2009,
	title = {A survey of robot learning from demonstration},
	volume = {57},
	url = {http://www.sciencedirect.com/science/article/pii/S0921889008001772},
	number = {5},
	urldate = {2016-10-31TZ},
	journal = {Robotics and autonomous systems},
	author = {Argall, Brenna D. and Chernova, Sonia and Veloso, Manuela and Browning, Brett},
	year = {2009},
	pages = {469--483}
}

@article{trafton_enabling_2005,
	title = {Enabling effective human-robot interaction using perspective-taking in robots},
	volume = {35},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1453694},
	number = {4},
	urldate = {2016-10-31TZ},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics-Part A: Systems and Humans},
	author = {Trafton, J. Gregory and Cassimatis, Nicholas L. and Bugajska, Magdalena D. and Brock, Derek P. and Mintz, Farilee E. and Schultz, Alan C.},
	year = {2005},
	pages = {460--470}
}

@article{mitchell_explanation-based_1993,
	title = {Explanation-based neural network learning for robot control},
	url = {https://pdfs.semanticscholar.org/9489/501aaf1eb5fdd757c879e95f990aa9cc0a7c.pdf},
	urldate = {2016-10-31TZ},
	journal = {Advances in neural information processing systems},
	author = {Mitchell, Tom M. and Thrun, Sebastian B. and {others}},
	year = {1993},
	pages = {287--287}
}

@article{papadimitriou_goal_nodate,
	title = {The {Goal} {Behind} the {Action}: {Towards} {Goal}-aware {Systems} and {Applications}},
	shorttitle = {The {Goal} {Behind} the {Action}},
	url = {https://disi.unitn.it/~velgias/docs/PapadimitriouKMV16.pdf},
	urldate = {2016-10-28TZ},
	author = {Papadimitriou, Dimitra and Koutrika, Georgia and Mylopoulos, John and Velegrakis, Yannis}
}

@incollection{lesh_using_1999,
	title = {Using plan recognition in human-computer collaboration},
	url = {http://link.springer.com/chapter/10.1007/978-3-7091-2490-1_3},
	urldate = {2016-10-28TZ},
	booktitle = {{UM}99 {User} {Modeling}},
	publisher = {Springer},
	author = {Lesh, Neal and Rich, Charles and Sidner, Candace L.},
	year = {1999},
	pages = {23--32}
}

@misc{noauthor_learning_nodate,
	title = {Learning to {Interact} and {Interacting} to {Learn}: {Active} {Statistical} {Learning} in {Human}-{Robot} {Interaction}},
	url = {http://www.indiana.edu/~dll/papers/ijcnn14.pdf},
	urldate = {2016-10-20TZ}
}

@article{dominey_basis_2011,
	series = {Special {Issue}: {Cognitive} {Robotics} and {Reevaluation} of {Piaget} {Concept} of {Egocentrism}},
	title = {The basis of shared intentions in human and robot cognition},
	volume = {29},
	issn = {0732-118X},
	url = {http://www.sciencedirect.com/science/article/pii/S0732118X09000373},
	doi = {10.1016/j.newideapsych.2009.07.006},
	abstract = {There is a fundamental difference between robots that are equipped with sensory, motor and cognitive capabilities, vs. simulations or non-embodied cognitive systems. Via their perceptual and motor capabilities, these robotic systems can interact with humans in an increasingly more “natural” way, physically interacting with shared objects in cooperative action settings. Indeed, such cognitive robotic systems provide a unique opportunity to developmental psychologists for implementing their theories and testing their hypotheses on systems that are becoming increasingly “at home” in the sensory--motor and social worlds, where such hypotheses are relevant. The current research is the result of interaction between research in computational neuroscience and robotics on the one hand, and developmental psychology on the other. One of the key findings in the developmental psychology context is that with respect to other primates, humans appear to have a unique ability and motivation to share goals and intentions with others. This ability is expressed in cooperative behavior very early in life, and appears to be the basis for subsequent development of social cognition. Here we attempt to identify a set of core functional elements of cooperative behavior and the corresponding shared intentional representations. We then begin to specify how these capabilities can be implemented in a robotic system, the Cooperator, and tested in human–robot interaction experiments. Based on the results of these experiments we discuss the mutual benefit for both fields of the interaction between robotics and developmental psychology.},
	number = {3},
	urldate = {2016-10-20TZ},
	journal = {New Ideas in Psychology},
	author = {Dominey, Peter Ford and Warneken, Felix},
	month = dec,
	year = {2011},
	pages = {260--274}
}

@misc{noauthor_motor_nodate,
	title = {From {Motor} {Learning} to {Interaction} {Learning} in {Robots}},
	url = {http://is.tuebingen.mpg.de/fileadmin/user_upload/files/publications/JNRR2009-Sigaud_[0].pdf},
	urldate = {2016-10-20TZ}
}

@inproceedings{lallee_towards_2011,
	title = {Towards a platform-independent cooperative human-robot interaction system: {Ii}. perception, execution and imitation of goal directed actions},
	shorttitle = {Towards a platform-independent cooperative human-robot interaction system},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6094744},
	urldate = {2016-10-24TZ},
	booktitle = {2011 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	publisher = {IEEE},
	author = {Lallée, Stephane and Pattacini, Ugo and Boucher, Jean David and Lemaignan, Séverin and Lenz, Alexander and Melhuish, Chris and Natale, Lorenzo and Skachek, Sergey and Hamann, Katharina and Steinwender, Jasmin and {others}},
	year = {2011},
	pages = {2895--2902}
}

@inproceedings{pointeau_robot_2013,
	title = {Robot learning rules of games by extraction of intrinsic properties},
	url = {http://www.sbri.fr/files/publications/pointeau%2013%20achi.pdf},
	urldate = {2016-10-24TZ},
	booktitle = {The {Sixth} {International} {Conference} on {Advances} in {Computer}-{Human} {Interactions}, {ACHI}},
	author = {Pointeau, Grégoire and Petit, Maxime and Dominey, Peter Ford},
	year = {2013},
	pages = {109--116}
}

@inproceedings{pointeau_embodied_2013,
	title = {Embodied simulation based on autobiographical memory},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-39802-5_21},
	urldate = {2016-10-24TZ},
	booktitle = {Conference on {Biomimetic} and {Biohybrid} {Systems}},
	publisher = {Springer},
	author = {Pointeau, Gregoire and Petit, Maxime and Dominey, Peter Ford},
	year = {2013},
	pages = {240--250}
}

@article{pointeau_successive_2014,
	title = {Successive {Developmental} {Levels} of {Autobiographical} {Memory} for {Learning} {Through} {Social} {Interaction}},
	volume = {6},
	issn = {1943-0604},
	doi = {10.1109/TAMD.2014.2307342},
	abstract = {A developing cognitive system will ideally acquire knowledge of its interaction in the world, and will be able to use that knowledge to construct a scaffolding for progressively structured levels of behavior. The current research implements and tests an autobiographical memory system by which a humanoid robot, the iCub, can accumulate its experience in interacting with humans, and extract regularities that characterize this experience. This knowledge is then used in order to form composite representations of common experiences. We first apply this to the development of knowledge of spatial locations, and relations between objects in space. We then demonstrate how this can be extended to temporal relations between events, including “before” and “after,” which structure the occurrence of events in time. In the system, after extended sessions of interaction with a human, the resulting accumulated experience is processed in an offline manner, in a form of consolidation, during which common elements of different experiences are generalized in order to generate new meanings. These learned meanings then form the basis for simple behaviors that, when encoded in the autobiographical memory, can form the basis for memories of shared experiences with the human, and which can then be reused as a form of game playing or shared plan execution.},
	number = {3},
	journal = {IEEE Transactions on Autonomous Mental Development},
	author = {Pointeau, G. and Petit, M. and Dominey, P. F.},
	month = sep,
	year = {2014},
	pages = {200--212}
}

@article{pitti_neural_2013,
	title = {Neural model for learning-to-learn of novel task sets in the motor domain},
	volume = {4},
	issn = {1664-1078},
	url = {http://journal.frontiersin.org/article/10.3389/fpsyg.2013.00771/abstract},
	doi = {10.3389/fpsyg.2013.00771},
	urldate = {2016-10-24TZ},
	journal = {Frontiers in Psychology},
	author = {Pitti, Alexandre and Braud, Raphaël and Mahé, Sylvain and Quoy, Mathias and Gaussier, Philippe},
	year = {2013}
}

@article{nomikou_constructing_2016,
	title = {Constructing {Interaction}: {The} {Development} of {Gaze} {Dynamics}},
	volume = {25},
	issn = {1522-7219},
	shorttitle = {Constructing {Interaction}},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/icd.1975/abstract},
	doi = {10.1002/icd.1975},
	abstract = {Gaze is one of the first and most important means of communication and coordination in parent–infant dyads. In the present paper we used a novel method, designed to discover patterns in time-series, to investigate the dynamics of gaze in dyads and its developmental change. Using a longitudinal corpus of natural interactions, mutual mother–infant gaze was coded when the infants were 3, 6, and 8 months old and subjected to recurrence analysis. The cross-recurrence profiles obtained for the three time points show systematic differences: While the engagement in mutual gaze decreases with age, the behaviour becomes more tightly coupled as a more regular temporal structure emerges. We suggest that this stronger interdependency of gaze behaviour may indicate the development of a social feedback loop enabling engagement in interaction. Copyright © 2016 John Wiley \& Sons, Ltd.},
	language = {en},
	number = {3},
	urldate = {2016-10-24TZ},
	journal = {Infant and Child Development},
	author = {Nomikou, Iris and Leonardi, Giuseppe and Rohlfing, Karharina J. and Rączaszek-Leonardi, Joanna},
	month = may,
	year = {2016},
	pages = {277--295}
}

@article{scassellati_theory_nodate,
	title = {Theory of {Mind} for a {Humanoid} {Robot}},
	volume = {12},
	issn = {0929-5593, 1573-7527},
	url = {http://link.springer.com/article/10.1023/A:1013298507114},
	doi = {10.1023/A:1013298507114},
	abstract = {If we are to build human-like robots that can interact naturally with people, our robots must know not only about the properties of objects but also the properties of animate agents in the world. One of the fundamental social skills for humans is the attribution of beliefs, goals, and desires to other people. This set of skills has often been called a “theory of mind.” This paper presents the theories of Leslie (1994) and Baron-Cohen (1995) on the development of theory of mind in human children and discusses the potential application of both of these theories to building robots with similar capabilities. Initial implementation details and basic skills (such as finding faces and eyes and distinguishing animate from inanimate stimuli) are introduced. I further speculate on the usefulness of a robotic implementation in evaluating and comparing these two models.},
	language = {en},
	number = {1},
	urldate = {2016-10-24TZ},
	journal = {Autonomous Robots},
	author = {Scassellati, Brian},
	pages = {13--24}
}

@article{cakmak_designing_2010,
	title = {Designing {Interactions} for {Robot} {Active} {Learners}},
	volume = {2},
	issn = {1943-0604},
	doi = {10.1109/TAMD.2010.2051030},
	abstract = {This paper addresses some of the problems that arise when applying active learning to the context of human-robot interaction (HRI). Active learning is an attractive strategy for robot learners because it has the potential to improve the accuracy and the speed of learning, but it can cause issues from an interaction perspective. Here we present three interaction modes that enable a robot to use active learning queries. The three modes differ in when they make queries: the first makes a query every turn, the second makes a query only under certain conditions, and the third makes a query only when explicitly requested by the teacher. We conduct an experiment in which 24 human subjects teach concepts to our upper-torso humanoid robot, Simon, in each interaction mode, and we compare these modes against a baseline mode using only passive supervised learning. We report results from both a learning and an interaction perspective. The data show that the three modes using active learning are preferable to the mode using passive supervised learning both in terms of performance and human subject preference, but each mode has advantages and disadvantages. Based on our results, we lay out several guidelines that can inform the design of future robotic systems that use active learning in an HRI setting.},
	number = {2},
	journal = {IEEE Transactions on Autonomous Mental Development},
	author = {Cakmak, M. and Chao, C. and Thomaz, A. L.},
	month = jun,
	year = {2010},
	pages = {108--118}
}

@inproceedings{oudah_learning_2015,
	address = {New York, NY, USA},
	series = {{HRI} '15},
	title = {Learning to {Interact} with a {Human} {Partner}},
	isbn = {978-1-4503-2883-8},
	url = {http://doi.acm.org/10.1145/2696454.2696482},
	doi = {10.1145/2696454.2696482},
	abstract = {Despite the importance of mutual adaption in human relationships, online learning is not yet used during most successful human-robot interactions. The lack of online learning in HRI to date can be attributed to at least two unsolved challenges: random exploration (a core component of most online-learning algorithms) and the slow convergence rates of previous online-learning algorithms. However, several recently developed online-learning algorithms have been reported to learn at much faster rates than before, which makes them candidates for use in human-robot interactions. In this paper, we explore the ability of these algorithms to learn to interact with people. Via user study, we show that these algorithms alone do not consistently learn to collaborate with human partners. Similarly, we observe that humans fail to consistently collaborate with each other in the absence of explicit communication. However, we demonstrate that one algorithm does learn to effectively collaborate with people when paired with a novel cheap-talk communication system. In addition to this technical achievement, this work highlights the need to address AI and HRI synergistically rather than independently.},
	urldate = {2016-10-20TZ},
	booktitle = {Proceedings of the {Tenth} {Annual} {ACM}/{IEEE} {International} {Conference} on {Human}-{Robot} {Interaction}},
	publisher = {ACM},
	author = {Oudah, Mayada and Babushkin, Vahan and Chenlinangjia, Tennom and Crandall, Jacob W.},
	year = {2015},
	pages = {311--318}
}

@inproceedings{wrede_towards_2012,
	address = {Osaka, Japan},
	title = {Towards robots with teleological action and language understanding},
	url = {https://hal.inria.fr/hal-00788627},
	abstract = {It is generally agreed upon that in order to achieve generalizable learning capabilities of robots they need to be able to acquire compositional structures - whether in language or in action. However, in human development the capability to perceive compositional structure only evolves at a later stage. Before the capability to understand action and language in a structured, compositional way arises, infants learn in a holistic way which enables them to interact in a socially adequate way with their social and physical environment even with very limited understanding of the world, e.g. trying to take part in games without knowing the exact rules. This capability endows them with an action production advantage which elicits corrective feedback from a tutor, thus reducing the search space of possible action interpretations tremendously. In accordance with findings from developmental psychology we argue that this holistic way is in fact a teleological representation encoding a goal-directed per- ception of actions facilitated through communicational frames. This observation leads to a range of consequences which need to be verfied and analysed in further research. Here, we discuss two hypotheses how this can be made accessible for action learning in robots: (1) We explore the idea that the teleological approach allows some kind of highly reduced one shot learning enabling the learner to perform a meaningful, although only partially "correct" action which can then be further refined through compositional approaches. (2) We discuss the possibility to transfer the concept of "conversational frames" as recurring interaction patterns to the action domain, thus facilitating to understand the meaning of a new action. We conclude that these capabilities need to be combined with more analytical compositional learning methods in order to achieve human-like learning performance.},
	urldate = {2016-10-20TZ},
	booktitle = {Humanoids 2012 {Workshop} on {Developmental} {Robotics}: {Can} developmental robotics yield human-like cognitive abilities?},
	author = {Wrede, Britta and Rohlfing, Katharina and Steil, Jochen and Wrede, Sebastian and Oudeyer, Pierre-Yves and Tani, Jun},
	editor = {Ugur, Emre and Nagai, Yukie and Oztop, Erhan and Asada, Minoru},
	month = nov,
	year = {2012}
}

@inproceedings{rohlfing_learning_2013,
	title = {Learning new words in unfamiliar frames from direct and indirect teaching},
	url = {https://www.researchgate.net/publication/261710060_Learning_new_words_in_unfamiliar_frames_from_direct_and_indirect_teaching},
	abstract = {In our study, we aimed at investigating how two years old children make use of the prag-matics in order to learn new words from an ongoing interaction. We operationalized the situational...},
	urldate = {2016-10-20TZ},
	booktitle = {{ResearchGate}},
	author = {Rohlfing, Katharina J. and Poblete, Juana Salas and Joublin, Frank},
	month = dec,
	year = {2013}
}

@inproceedings{peltason_pamini:_2010,
	address = {Stroudsburg, PA, USA},
	series = {{SIGDIAL} '10},
	title = {Pamini: {A} {Framework} for {Assembling} {Mixed}-initiative {Human}-robot {Interaction} from {Generic} {Interaction} {Patterns}},
	isbn = {978-1-932432-85-5},
	shorttitle = {Pamini},
	url = {http://dl.acm.org/citation.cfm?id=1944506.1944546},
	abstract = {Dialog modeling in robotics suffers from lack of generalizability, due to the fact that the dialog is heavily influenced by the tasks the robot is able to perform. We introduce interleaving interaction patterns together with a general protocol for task communication which enables us to systematically specify the relationship between dialog structure and task structure. We argue that this approach meets the requirements of advanced dialog modeling on robots and at the same time exhibits a better scalability than existing concepts.},
	urldate = {2016-10-20TZ},
	booktitle = {Proceedings of the 11th {Annual} {Meeting} of the {Special} {Interest} {Group} on {Discourse} and {Dialogue}},
	publisher = {Association for Computational Linguistics},
	author = {Peltason, Julia and Wrede, Britta},
	year = {2010},
	pages = {229--232}
}

@article{dominey_towards_2007,
	series = {Selected papers from the 3rd {International} {Conference} on {Development} and {Learning} ({ICDL} 2004){Time} series prediction competition: the {CATS} benchmark3rd {International} {Conference} on {Development} and {Learning}},
	title = {Towards a construction-based framework for development of language, event perception and social cognition: {Insights} from grounded robotics and simulation},
	volume = {70},
	issn = {0925-2312},
	shorttitle = {Towards a construction-based framework for development of language, event perception and social cognition},
	url = {http://www.sciencedirect.com/science/article/pii/S0925231206005182},
	doi = {10.1016/j.neucom.2006.02.030},
	abstract = {The current research addresses the question of how neurocomputational mechanisms developed for a given cognitive function can be adapted to novel functions. In this context, research in language development has contributed to the concept of grammatical construction defined in terms of a functional mapping between the surface structure of an utterance, and its meaning. The objective of the current research is to generalize this notion of construction, and demonstrate its possible application in two cognitive areas that are adjacent and related to language, notably the understanding of physical events based on vision, and the understanding of the intentions of other agents based on observation of their behavior in the context of a perceptually grounded robotic system.},
	number = {13–15},
	urldate = {2016-10-20TZ},
	journal = {Neurocomputing},
	author = {Dominey, Peter Ford},
	month = aug,
	year = {2007},
	pages = {2288--2302}
}

@inproceedings{vollmer_studying_2014,
	title = {Studying the co-construction of interaction protocols in collaborative tasks with humans},
	doi = {10.1109/DEVLRN.2014.6982983},
	abstract = {In interaction, humans align and effortlessly create common ground in communication, allowing efficient collaboration in widely diverse contexts. Robots are still far away from being able to adapt in such a flexible manner with non-expert humans to complete collaborative tasks. Challenges include the capability to understand unknown feedback or guidance signals, to make sense of what they refer to depending on their timing and context, and to agree on how to organize the interaction into roles and turns. As a first step in approaching this issue, we investigate here the processes used by humans to negotiate a protocol of interaction when they do not already share one. We introduce a new experimental setup, where two humans have to collaborate to solve a task. The channels of communication they can use are constrained and force them to invent and agree on a shared interaction protocol in order to solve the task. These constraints allow us to analyze how a communication protocol is progressively established through the interplay and history of individual actions. We report preliminary results obtained from a pilot study, and discuss how the understanding of strategies used by humans could be useful to achieve more flexible HRI.},
	booktitle = {4th {International} {Conference} on {Development} and {Learning} and on {Epigenetic} {Robotics}},
	author = {Vollmer, A. L. and Grizou, J. and Lopes, M. and Rohlfing, K. and Oudeyer, P. Y.},
	month = oct,
	year = {2014},
	pages = {208--215}
}

@article{breazeal_embodied_2009,
	title = {An {Embodied} {Cognition} {Approach} to {Mindreading} {Skills} for {Socially} {Intelligent} {Robots}},
	volume = {28},
	issn = {0278-3649, 1741-3176},
	url = {http://ijr.sagepub.com/content/28/5/656},
	doi = {10.1177/0278364909102796},
	abstract = {Future applications for personal robots motivate research into developing robots that are intelligent in their interactions with people. Toward this goal, in this paper we present an integrated socio-cognitive architecture to endow an anthropomorphic robot with the ability to infer mental states such as beliefs, intents, and desires from the observable behavior of its human partner. The design of our architecture is informed by recent findings from neuroscience and embodies cognition that reveals how living systems leverage their physical and cognitive embodiment through simulation-theoretic mechanisms to infer the mental states of others. We assess the robot's mindreading skills on a suite of benchmark tasks where the robot interacts with a human partner in a cooperative scenario and a learning scenario. In addition, we have conducted human subjects experiments using the same task scenarios to assess human performance on these tasks and to compare the robot's performance with that of people. In the process, our human subject studies also reveal some interesting insights into human behavior.},
	language = {en},
	number = {5},
	urldate = {2016-10-20TZ},
	journal = {The International Journal of Robotics Research},
	author = {Breazeal, Cynthia and Gray, Jesse and Berlin, Matt},
	month = may,
	year = {2009},
	pages = {656--680}
}

@book{teachers_experiments_nodate,
	title = {Experiments in {Socially} {Guided} {Exploration}: {Lessons} {Learned} in {Building} {Robots} that {Learn} with and without {Human} {Teachers}},
	shorttitle = {Experiments in {Socially} {Guided} {Exploration}},
	abstract = {We present a learning system, Socially Guided Exploration, in which a social robot learns new tasks through a combination of self-exploration and interpersonal interaction. The system’s motivational drives (novelty, mastery), along with social scaffolding from a human partner, bias behavior to create learning opportunities for a Reinforcement Learning mechanism. The robot is able to learn on its own, but can flexibly use the guidance of a human teacher to improve performance. We report the results of a series of experiments where the robot learns on its own in addition to being taught by human subjects. We analyze these interactions to understand human teaching behavior and the social dynamics of the human-teacher/robot-learner system. With respect to learning performance, human guidance results in a task set that is significantly more focused and efficient, while self-exploration results in a broader set. Analysis of human teaching behavior reveals insights of social coupling between human teacher and robot learner, different teaching styles, strong consistency in the kinds and frequency of scaffolding acts across teachers, and nuance in the communicative intent behind positive and negative feedback.},
	author = {Teachers, Without Human and Thomaz, Andrea L. and B, A. Cynthia Breazeal}
}

@incollection{griffith_policy_2013,
	title = {Policy {Shaping}: {Integrating} {Human} {Feedback} with {Reinforcement} {Learning}},
	shorttitle = {Policy {Shaping}},
	url = {http://papers.nips.cc/paper/5187-policy-shaping-integrating-human-feedback-with-reinforcement-learning.pdf},
	urldate = {2016-10-20TZ},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 26},
	publisher = {Curran Associates, Inc.},
	author = {Griffith, Shane and Subramanian, Kaushik and Scholz, Jonathan and Isbell, Charles and Thomaz, Andrea L},
	editor = {Burges, C. J. C. and Bottou, L. and Welling, M. and Ghahramani, Z. and Weinberger, K. Q.},
	year = {2013},
	pages = {2625--2633}
}

@book{steels_spatial_2008,
	address = {Oxford},
	title = {Spatial {Language} and {Dialogue}},
	publisher = {Oxford University Press},
	author = {Steels, Luc and Loetzsch, Martin},
	year = {2008}
}

@article{tzeng_towards_2015,
	title = {Towards {Adapting} {Deep} {Visuomotor} {Representations} from {Simulated} to {Real} {Environments}},
	url = {http://arxiv.org/abs/1511.07111},
	abstract = {We address the problem of adapting robotic perception from simulated to real-world environments. For many robotic control tasks, real training imagery is expensive to obtain, but a large number of synthetic images is easy to generate through simulation. We propose a method that adapts visual representations using a small number of paired synthetic and real views of the same scene. Our model generalizes prior approaches and combines a standard in-domain loss, a cross-domain adaptation loss, and a contrastive loss explicitly designed to align pairs of images in feature space. We presume a synthetic dataset comprised of views that are a superset of a small number of real views, where the alignment may be either explicit or latent. We evaluate our approach on a manipulation task and show that by exploiting the presence of synthetic-real image pairs, our model is able to compensate for domain shift more effectively than conventional initialization techniques. Our results serve as an initial step toward pretraining deep visuomotor policies entirely in simulation, significantly reducing physical demands when learning complex policies.},
	urldate = {2016-10-20TZ},
	journal = {arXiv:1511.07111 [cs]},
	author = {Tzeng, Eric and Devin, Coline and Hoffman, Judy and Finn, Chelsea and Peng, Xingchao and Levine, Sergey and Saenko, Kate and Darrell, Trevor},
	month = nov,
	year = {2015},
	note = {arXiv: 1511.07111}
}

@article{tomasello_understanding_2005,
	title = {Understanding and sharing intentions: the origins of cultural cognition},
	volume = {28},
	issn = {0140-525X},
	shorttitle = {Understanding and sharing intentions},
	doi = {10.1017/S0140525X05000129},
	abstract = {We propose that the crucial difference between human cognition and that of other species is the ability to participate with others in collaborative activities with shared goals and intentions: shared intentionality. Participation in such activities requires not only especially powerful forms of intention reading and cultural learning, but also a unique motivation to share psychological states with others and unique forms of cognitive representation for doing so. The result of participating in these activities is species-unique forms of cultural cognition and evolution, enabling everything from the creation and use of linguistic symbols to the construction of social norms and individual beliefs to the establishment of social institutions. In support of this proposal we argue and present evidence that great apes (and some children with autism) understand the basics of intentional action, but they still do not participate in activities involving joint intentions and attention (shared intentionality). Human children's skills of shared intentionality develop gradually during the first 14 months of life as two ontogenetic pathways intertwine: (1) the general ape line of understanding others as animate, goal-directed, and intentional agents; and (2) a species-unique motivation to share emotions, experience, and activities with other persons. The developmental outcome is children's ability to construct dialogic cognitive representations, which enable them to participate in earnest in the collectivity that is human cognition.},
	language = {ENG},
	number = {5},
	journal = {The Behavioral and Brain Sciences},
	author = {Tomasello, Michael and Carpenter, Malinda and Call, Josep and Behne, Tanya and Moll, Henrike},
	month = oct,
	year = {2005},
	pmid = {16262930},
	pages = {675--691; discussion 691--735}
}
@article{rohlfing_alternative_2016,
	title = {An {Alternative} to {Mapping} a {Word} onto a {Concept} in {Language} {Acquisition}: {Pragmatic} {Frames}},
	shorttitle = {An {Alternative} to {Mapping} a {Word} onto a {Concept} in {Language} {Acquisition}},
	url = {http://journal.frontiersin.org/article/10.3389/fpsyg.2016.00470/full},
	doi = {10.3389/fpsyg.2016.00470},
	abstract = {The classic mapping metaphor posits that children learn a word by mapping it onto a concept of an object or event. However, we believe that a mapping metaphor cannot account for word learning, because even though children focus attention on objects, they do not necessarily remember the connection between the word and the referent unless it is framed pragmatically, that is, within a task. Our theoretical paper proposes an alternative mechanism for word learning. Our main premise is that word learning occurs as children accomplish a goal in cooperation with a partner. We follow Bruner’s (1983) idea and further specify pragmatic frames as the learning units that drive language acquisition and cognitive development. These units consist of a sequence of actions and verbal behaviors that are co-constructed with a partner to achieve a joint goal. We elaborate on this alternative, offer some initial parametrizations of the concept, and embed it in current language learning approaches.},
	urldate = {2016-10-20TZ},
	journal = {Cognitive Science},
	author = {Rohlfing, Katharina J. and Wrede, Britta and Vollmer, Anna-Lisa and Oudeyer, Pierre-Yves},
	year = {2016},
	pages = {470}
}

@article{zhang_towards_2015,
	title = {Towards {Vision}-{Based} {Deep} {Reinforcement} {Learning} for {Robotic} {Motion} {Control}},
	url = {http://arxiv.org/abs/1511.03791},
	abstract = {This paper introduces a machine learning based system for controlling a robotic manipulator with visual perception only. The capability to autonomously learn robot controllers solely from raw-pixel images and without any prior knowledge of configuration is shown for the first time. We build upon the success of recent deep reinforcement learning and develop a system for learning target reaching with a three-joint robot manipulator using external visual observation. A Deep Q Network (DQN) was demonstrated to perform target reaching after training in simulation. Transferring the network to real hardware and real observation in a naive approach failed, but experiments show that the network works when replacing camera images with synthetic images.},
	urldate = {2016-10-20TZ},
	journal = {arXiv:1511.03791 [cs]},
	author = {Zhang, Fangyi and Leitner, Jürgen and Milford, Michael and Upcroft, Ben and Corke, Peter},
	month = nov,
	year = {2015},
	note = {arXiv: 1511.03791},
	keywords = {deep reinforcement learning, robot task learning}
}

@inproceedings{loftin_learning_2014,
	title = {Learning something from nothing: {Leveraging} implicit human feedback strategies},
	isbn = {978-1-4799-6765-0 978-1-4799-6763-6},
	shorttitle = {Learning something from nothing},
	url = {http://ieeexplore.ieee.org/document/6926319/},
	doi = {10.1109/ROMAN.2014.6926319},
	urldate = {2016-10-20TZ},
	publisher = {IEEE},
	author = {Loftin, Robert and Peng, Bei and MacGlashan, James and Littman, Michael L. and Taylor, Matthew E. and Huang, Jeff and Roberts, David L.},
	month = aug,
	year = {2014},
	pages = {607--612}
}

@article{james_3d_2016,
	title = {3D {Simulation} for {Robot} {Arm} {Control} with {Deep} {Q}-{Learning}},
	url = {http://arxiv.org/abs/1609.03759},
	abstract = {Intelligent control of robotic arms has huge potential over the coming years, but as of now will often fail to adapt when presented with new and unfamiliar environments. Recent trends to solve this problem have seen a shift to end-to-end solutions using deep reinforcement learning to learn policies from visual input, rather than relying on a handcrafted, modular pipeline. Building upon the recent success of deep Q-networks, we present an approach which uses three-dimensional simulations to train a 7-DOF robotic arm in a robot arm control task without any prior knowledge. Policies accept images of the environment as input and output motor actions. However, the high-dimensionality of the policies as well as the large state space makes policy search difficult. This is overcome by ensuring interesting states are explored via intermediate rewards that guide the policy towards higher reward states. Our results demonstrate that deep Q-networks can be used to learn policies for a task that involves locating a cube, grasping, and then finally lifting. The agent is able to learn to deal with a range of starting joint configurations and starting cube positions when tested in simulation. Moreover, we show that policies trained via simulation have the potential to be directly applied to real-world equivalents without any further training. We believe that robot simulations can decrease the dependency on physical robots and ultimately improve productivity of training robot control tasks.},
	urldate = {2016-10-18TZ},
	journal = {arXiv:1609.03759 [cs]},
	author = {James, Stephen and Johns, Edward},
	month = sep,
	year = {2016},
	note = {arXiv: 1609.03759},
	keywords = {deep reinforcement learning, robot task learning}
}

@article{vogt_modeling_2010,
	title = {Modeling social learning of language and skills},
	volume = {16},
	issn = {1064-5462},
	doi = {10.1162/artl_a_00007},
	abstract = {We present a model of social learning of both language and skills, while assuming—insofar as possible—strict autonomy, virtual embodiment, and situatedness. This model is built by integrating various previous models of language development and social learning, and it is this integration that, under the mentioned assumptions, provides novel challenges. The aim of the article is to investigate what sociocognitive mechanisms agents should have in order to be able to transmit language from one generation to the next so that it can be used as a medium to transmit internalized rules that represent skill knowledge. We have performed experiments where this knowledge solves the familiar poisonous-food problem. Simulations reveal under what conditions, regarding population structure, agents can successfully solve this problem. In addition to issues relating to perspective taking and mutual exclusivity, we show that agents need to coordinate interactions so that they can establish joint attention in order to form a scaffold for language learning, which in turn forms a scaffold for the learning of rule-based skills. Based on these findings, we conclude by hypothesizing that social learning at one level forms a scaffold for the social learning at another, higher level, thus contributing to the accumulation of cultural knowledge.},
	language = {ENG},
	number = {4},
	journal = {Artificial Life},
	author = {Vogt, Paul and Haasdijk, Evert},
	year = {2010},
	pmid = {20662596},
	keywords = {developmental robotics, interactive learning, language, robot robot interaction, robot task learning},
	pages = {289--309}
}

@article{schaul_prioritized_2015,
	title = {Prioritized {Experience} {Replay}},
	url = {http://arxiv.org/abs/1511.05952},
	abstract = {Experience replay lets online reinforcement learning agents remember and reuse experiences from the past. In prior work, experience transitions were uniformly sampled from a replay memory. However, this approach simply replays transitions at the same frequency that they were originally experienced, regardless of their significance. In this paper we develop a framework for prioritizing experience, so as to replay important transitions more frequently, and therefore learn more efficiently. We use prioritized experience replay in Deep Q-Networks (DQN), a reinforcement learning algorithm that achieved human-level performance across many Atari games. DQN with prioritized experience replay achieves a new state-of-the-art, outperforming DQN with uniform replay on 41 out of 49 games.},
	urldate = {2016-10-10TZ},
	journal = {arXiv:1511.05952 [cs]},
	author = {Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
	month = nov,
	year = {2015},
	note = {arXiv: 1511.05952},
	keywords = {Computer Science - Learning}
}

@article{amershi_power_2014,
	title = {Power to the {People}: {The} {Role} of {Humans} in {Interactive} {Machine} {Learning}},
	shorttitle = {Power to the {People}},
	url = {https://www.microsoft.com/en-us/research/publication/power-to-the-people-the-role-of-humans-in-interactive-machine-learning/},
	abstract = {Systems that can learn interactively from their end-users are quickly becoming widespread. Until recently, this progress has been fueled mostly by advances in machine learning; however, more and more researchers are realizing the importance of studying users of these systems. In this article we promote this approach and demonstrate how it can result in better …},
	urldate = {2016-10-13TZ},
	journal = {AI Magazine},
	author = {Amershi, Saleema and Cakmak, Maya and Knox, W. Bradley and Kulesza, Todd},
	month = dec,
	year = {2014}
}

@phdthesis{lin_reinforcement_1992,
	address = {Pittsburgh, PA, USA},
	title = {Reinforcement {Learning} for {Robots} {Using} {Neural} {Networks}},
	abstract = {Reinforcement learning agents are adaptive, reactive, and self-supervised. The aim of this dissertation is to extend the state of the art of reinforcement learning and enable its applications to complex robot-learning problems. In particular, it focuses on two issues. First, learning from sparse and delayed reinforcement signals is hard and in general a slow process. Techniques for reducing learning time must be devised. Second, most existing reinforcement learning methods assume that the world is a Markov decision process. This assumption is too strong for many robot tasks of interest.This dissertation demonstrates how we can possibly overcome the slow learning problem and tackle non-Markovian environments, making reinforcement learning more practical for realistic robot tasks: (1) Reinforcement learning can be naturally integrated with artificial neural networks to obtain high-quality generalization, resulting in a significant learning speedup. Neural networks are used in this dissertation, and they generalize effectively even in the presence of noise and a large of binary and real-valued inputs. (2) Reinforcement learning agents can save many learning trials by using an action model, which can be learned on-line. With a model, an agent can mentally experience the effects of its actions without actually executing them. Experience replay is a simple technique that implements this idea, and is shown to be effective in reducing the number of action executions required. (3) Reinforcement learning agents can take advantage of instructive training instances provided by human teachers, resulting in a significant learning speedup. Teaching can also help learning agents avoid local optima during the search for optimal control. Simulation experiments indicate that even a small amount of teaching can save agents many learning trials. (4) Reinforcement learning agents can significantly reduce learning time by hierarchical learning--they first solve elementary learning problems and then combine solutions to the elementary problems to solve a complex problem. Simulation experiments indicate that a robot with hierarchical learning can solve a complex problem, which otherwise is hardly solvable within a reasonable time. (5) Reinforcement learning agents can deal with a wide range of non-Markovian environments by having a memory of their past. Three memory architectures are discussed. They work reasonably well for a variety of simple problems. One of them is also successfully applied to a nontrivial non-Markovian robot task.The results of this dissertation rely on computer simulation, including (1) an agent operating in a dynamic and hostile environment and (2) a mobile robot operating in a noisy and non-Markovian environment. The robot simulator is physically realistic. This dissertation concludes that it is possible to build artificial agents than can acquire complex control policies effectively by reinforcement learning.},
	school = {Carnegie Mellon University},
	author = {Lin, Long-Ji},
	year = {1992},
	note = {UMI Order No. GAX93-22750}
}

@phdthesis{grizou_learning_2014,
	type = {phdthesis},
	title = {Learning from {Unlabeled} {Interaction} {Frames}},
	url = {https://hal.inria.fr/tel-01095562/document},
	abstract = {This thesis investigates how a machine can be taught a new task from unlabeled human instructions, which is without knowing beforehand how to associate the human communicative signals with their meanings. The theoretical and empirical work presented in this thesis provides means to create calibration free interactive systems, which allow humans to interact with machines, from scratch, using their own preferred teaching signals. It therefore removes the need for an expert to tune the system for each specific user, which constitutes an important step towards flexible personalized teaching interfaces, a key for the future of personal robotics.Our approach assumes the robot has access to a limited set of task hypotheses, which include the task the user wants to solve. Our method consists of generating interpretation hypotheses of the teaching signals with respect to each hypothetic task. By building a set of hypothetic interpretation, i.e. a set of signal-label pairs for each task, the task the user wants to solve is the one that explains better the history of interaction.We consider different scenarios, including a pick and place robotics experiment with speech as the modality of interaction, and a navigation task in a brain computer interaction scenario. In these scenarios, a teacher instructs a robot to perform a new task using initially unclassified signals, whose associated meaning can be a feedback (correct/incorrect) or a guidance (go left, right, up, {\textbackslash}ldots). Our results show that a) it is possible to learn the meaning of unlabeled and noisy teaching signals, as well as a new task at the same time, and b) it is possible to reuse the acquired knowledge about the teaching signals for learning new tasks faster. We further introduce a planning strategy that exploits uncertainty from the task and the signals' meanings to allow more efficient learning sessions. We present a study where several real human subjects control successfully a virtual device using their brain and without relying on a calibration phase. Our system identifies, from scratch, the target intended by the user as well as the decoder of brain signals.Based on this work, but from another perspective, we introduce a new experimental setup to study how humans behave in asymmetric collaborative tasks. In this setup, two humans have to collaborate to solve a task but the channels of communication they can use are constrained and force them to invent and agree on a shared interaction protocol in order to solve the task. These constraints allow analyzing how a communication protocol is progressively established through the interplay and history of individual actions.},
	language = {en},
	urldate = {2016-10-13TZ},
	school = {Université de Bordeaux},
	author = {Grizou, Jonathan},
	month = oct,
	year = {2014},
	keywords = {interactive learning, pragmatic frames}
}

@article{lake_building_2016,
	title = {Building {Machines} {That} {Learn} and {Think} {Like} {People}},
	url = {http://arxiv.org/abs/1604.00289},
	abstract = {Recent progress in artificial intelligence (AI) has renewed interest in building systems that learn and think like people. Many advances have come from using deep neural networks trained end-to-end in tasks such as object recognition, video games, and board games, achieving performance that equals or even beats humans in some respects. Despite their biological inspiration and performance achievements, these systems differ from human intelligence in crucial ways. We review progress in cognitive science suggesting that truly human-like learning and thinking machines will have to reach beyond current engineering trends in both what they learn, and how they learn it. Specifically, we argue that these machines should (a) build causal models of the world that support explanation and understanding, rather than merely solving pattern recognition problems; (b) ground learning in intuitive theories of physics and psychology, to support and enrich the knowledge that is learned; and (c) harness compositionality and learning-to-learn to rapidly acquire and generalize knowledge to new tasks and situations. We suggest concrete challenges and promising routes towards these goals that can combine the strengths of recent neural network advances with more structured cognitive models.},
	urldate = {2016-10-13TZ},
	journal = {arXiv:1604.00289 [cs, stat]},
	author = {Lake, Brenden M. and Ullman, Tomer D. and Tenenbaum, Joshua B. and Gershman, Samuel J.},
	month = apr,
	year = {2016},
	note = {arXiv: 1604.00289},
	keywords = {developmental robotics}
}

@article{vinciarelli_bridging_2012,
	title = {Bridging the {Gap} {Between} {Social} {Animal} and {Unsocial} {Machine}: {A} {Survey} of {Social} {Signal} {Processing}},
	volume = {3},
	issn = {1949-3045},
	shorttitle = {Bridging the {Gap} {Between} {Social} {Animal} and {Unsocial} {Machine}},
	url = {http://dx.doi.org/10.1109/T-AFFC.2011.27},
	doi = {10.1109/T-AFFC.2011.27},
	abstract = {Social Signal Processing is the research domain aimed at bridging the social intelligence gap between humans and machines. This paper is the first survey of the domain that jointly considers its three major aspects, namely, modeling, analysis, and synthesis of social behavior. Modeling investigates laws and principles underlying social interaction, analysis explores approaches for automatic understanding of social exchanges recorded with different sensors, and synthesis studies techniques for the generation of social behavior via various forms of embodiment. For each of the above aspects, the paper includes an extensive survey of the literature, points to the most important publicly available resources, and outlines the most fundamental challenges ahead.},
	number = {1},
	urldate = {2016-10-13TZ},
	journal = {IEEE Trans. Affect. Comput.},
	author = {Vinciarelli, Alessandro and Pantic, Maja and Heylen, Dirk and Pelachaud, Catherine and Poggi, Isabella and D'Errico, Francesca and Schroeder, Marc},
	month = jan,
	year = {2012},
	keywords = {human robot interaction, social robots},
	pages = {69--87}
}

@book{thomaz_teachable_nodate,
	title = {Teachable {Robots}: {Understanding} {Human} {Teaching} {Behavior} to {Build} {More} {Effective} {Robot} {Learners}},
	shorttitle = {Teachable {Robots}},
	abstract = {While Reinforcement Learning (RL) is not traditionally designed for interactive supervisory input from a human teacher, several works in both robot and software agents have adapted it for human input by letting a human trainer control the reward signal. In this work, we experimentally examine the assumption underlying these works, namely that the human-given reward is compatible with the traditional RL reward signal. We describe an experimental platform with a simulated RL robot and present an analysis of real-time human teaching behavior found in a study in which untrained subjects taught the robot to perform a new task. We report three main observations on how people administer feedback when teaching a robot a task through Reinforcement Learning: (a) they use the reward channel not only for feedback, but also for future-directed guidance; (b) they have a positive bias to their feedback — possibly using the signal as a motivational channel; and (c) they change their behavior as they develop a mental model of the robotic learner. Given this, we made specific modifications to the simulated RL robot, and analyzed and evaluated its learning behavior in four additional experiments with human trainers. We report significant improvements on several learning measures. This work demonstrates the importance of understanding the human-teacher/robot-learner partnership in order to design algorithms that support how people want to teach while simultaneously improving the robot’s learning behavior.},
	author = {Thomaz, Andrea L. and Breazeal, Cynthia}
}

@inproceedings{grizou_robot_2013,
	address = {Osaka, Japan},
	title = {Robot {Learning} {Simultaneously} a {Task} and {How} to {Interpret} {Human} {Instructions}},
	url = {https://hal.archives-ouvertes.fr/hal-00850703},
	abstract = {This paper presents an algorithm to bootstrap shared understanding in a human-robot interaction scenario where the user teaches a robot a new task using teaching instructions yet unknown to it. In such cases, the robot needs to estimate simultaneously what the task is and the associated meaning of instructions received from the user. For this work, we consider a scenario where a human teacher uses initially unknown spoken words, whose associated unknown meaning is either a feedback (good/bad) or a guidance (go left, right, ...). We present computational results, within an inverse reinforcement learning framework, showing that a) it is possible to learn the meaning of unknown and noisy teaching instructions, as well as a new task at the same time, b) it is possible to reuse the acquired knowledge about instructions for learning new tasks, and c) even if the robot initially knows some of the instructions' meanings, the use of extra unknown teaching instructions improves learning efficiency.},
	urldate = {2016-10-12TZ},
	booktitle = {Joint {IEEE} {International} {Conference} on {Development} and {Learning} an on {Epigenetic} {Robotics} ({ICDL}-{EpiRob})},
	author = {Grizou, Jonathan and Lopes, Manuel and Oudeyer, Pierre-Yves},
	month = aug,
	year = {2013},
	keywords = {interactive learning, learning theory, robot task learning}
}

@inproceedings{grizou_interactive_2014,
	title = {Interactive {Learning} from {Unlabeled} {Instructions}},
	url = {https://hal.archives-ouvertes.fr/hal-01007689/document},
	abstract = {Interactive learning deals with the problem of learning and solving tasks using human instructions. It is common in human-robot interaction, tutoring systems, and in human-computer interfaces such as brain-computer ones. In most cases, learning these tasks is possible because the signals are predefined or an ad-hoc calibration procedure allows to map signals to specific meanings. In this paper, we address the problem of simultaneously solving a task under human feedback and learning the associated meanings of the feedback signals. This has important practical application since the user can start controlling a device from scratch, without the need of an expert to define the meaning of signals or carrying out a calibration phase. The paper proposes an algorithm that simultaneously assign meanings to signals while solving a sequential task under the assumption that both, human and machine, share the same a priori on the possible instruction meanings and the possible tasks. Furthermore, we show using synthetic and real EEG data from a brain-computer interface that taking into account the uncertainty of the task and the signal is necessary for the machine to actively plan how to solve the task efficiently.},
	language = {en},
	urldate = {2016-10-12TZ},
	author = {Grizou, Jonathan and Iturrate, Iñaki and Montesano, Luis and Oudeyer, Pierre-Yves and Lopes, Manuel},
	month = jul,
	year = {2014},
	keywords = {interactive learning},
	pages = {1--8}
}

@inproceedings{cederborg_policy_2015,
	address = {Buenos Aires, Argentina},
	series = {{IJCAI}'15},
	title = {Policy {Shaping} with {Human} {Teachers}},
	isbn = {978-1-57735-738-4},
	url = {http://dl.acm.org/citation.cfm?id=2832581.2832718},
	abstract = {In this work we evaluate the performance of a policy shaping algorithm using 26 human teachers. We examine if the algorithm is suitable for human-generated data on two different boards in a pac-man domain, comparing performance to an oracle that provides critique based on one known winning policy. Perhaps surprisingly, we show that the data generated by our 26 participants yields even better performance for the agent than data generated by the oracle. This might be because humans do not discourage exploring multiple winning policies. Additionally, we evaluate the impact of different verbal instructions, and different interpretations of silence, finding that the usefulness of data is affected both by what instructions is given to teachers, and how the data is interpreted.},
	urldate = {2016-10-13TZ},
	booktitle = {Proceedings of the 24th {International} {Conference} on {Artificial} {Intelligence}},
	publisher = {AAAI Press},
	author = {Cederborg, Thomas and Grover, Ishaan and Isbell, Charles L. and Thomaz, Andrea L.},
	year = {2015},
	keywords = {interactive learning, reinforcement learning},
	pages = {3366--3372}
}

@article{cederborg_social_2014,
	title = {A social learning formalism for learners trying to figure out what a teacher wants them to do},
	volume = {5},
	issn = {2081-4836},
	url = {http://www.degruyter.com/view/j/pjbr.2014.5.issue-1/pjbr-2014-0005/pjbr-2014-0005.xml},
	doi = {10.2478/pjbr-2014-0005},
	number = {1},
	urldate = {2016-10-10TZ},
	journal = {Paladyn, Journal of Behavioral Robotics},
	author = {Cederborg, Thomas and Oudeyer, Pierre-Yves},
	month = jan,
	year = {2014},
	keywords = {human robot interaction, interactive learning, learning theory}
}

@inproceedings{thomaz_reinforcement_2006,
	address = {Boston, Massachusetts},
	series = {{AAAI}'06},
	title = {Reinforcement {Learning} with {Human} {Teachers}: {Evidence} of {Feedback} and {Guidance} with {Implications} for {Learning} {Performance}},
	isbn = {978-1-57735-281-5},
	shorttitle = {Reinforcement {Learning} with {Human} {Teachers}},
	url = {http://dl.acm.org/citation.cfm?id=1597538.1597696},
	abstract = {As robots become a mass consumer product, they will need to learn new skills by interacting with typical human users. Past approaches have adapted reinforcement learning (RL) to accept a human reward signal; however, we question the implicit assumption that people shall only want to give the learner feedback on its past actions. We present findings from a human user study showing that people use the reward signal not only to provide feedback about past actions, but also to provide future directed rewards to guide subsequent actions. Given this, we made specific modifications to the simulated RL robot to incorporate guidance. We then analyze and evaluate its learning performance in a second user study, and we report significant improvements on several measures. This work demonstrates the importance of understanding the human-teacher/robot-learner system as a whole in order to design algorithms that support how people want to teach while simultaneously improving the robot's learning performance.},
	urldate = {2016-10-10TZ},
	booktitle = {Proceedings of the 21st {National} {Conference} on {Artificial} {Intelligence} - {Volume} 1},
	publisher = {AAAI Press},
	author = {Thomaz, Andrea L. and Breazeal, Cynthia},
	year = {2006},
	pages = {1000--1005}
}

@article{vinciarelli_social_2009,
	series = {Visual and multimodal analysis of human spontaneous behaviour:},
	title = {Social signal processing: {Survey} of an emerging domain},
	volume = {27},
	issn = {0262-8856},
	shorttitle = {Social signal processing},
	url = {http://www.sciencedirect.com/science/article/pii/S0262885608002485},
	doi = {10.1016/j.imavis.2008.11.007},
	abstract = {The ability to understand and manage social signals of a person we are communicating with is the core of social intelligence. Social intelligence is a facet of human intelligence that has been argued to be indispensable and perhaps the most important for success in life. This paper argues that next-generation computing needs to include the essence of social intelligence – the ability to recognize human social signals and social behaviours like turn taking, politeness, and disagreement – in order to become more effective and more efficient. Although each one of us understands the importance of social signals in everyday life situations, and in spite of recent advances in machine analysis of relevant behavioural cues like blinks, smiles, crossed arms, laughter, and similar, design and development of automated systems for social signal processing (SSP) are rather difficult. This paper surveys the past efforts in solving these problems by a computer, it summarizes the relevant findings in social psychology, and it proposes a set of recommendations for enabling the development of the next generation of socially aware computing.},
	number = {12},
	urldate = {2016-10-10TZ},
	journal = {Image and Vision Computing},
	author = {Vinciarelli, Alessandro and Pantic, Maja and Bourlard, Hervé},
	month = nov,
	year = {2009},
	pages = {1743--1759}
}

@book{droniou_apprentissage_2015,
	title = {Apprentissage de représentations et robotique développementale : quelques apports de l'apprentissage profond pour la robotique autonome},
	shorttitle = {Apprentissage de représentations et robotique développementale},
	url = {http://www.theses.fr/2015PA066056},
	abstract = {Afin de pouvoir évoluer de manière autonome et sûre dans leur environnement, les robots doivent être capables d'en construire un modèle fiable et pertinent. Pour des tâches variées dans des environnements complexes, il est difficile de prévoir de manière exhaustive les capacités nécessaires au robot. Il est alors intéressant de doter les robots de mécanismes d'apprentissage leur donnant la possibilité de construire eux-mêmes des représentations adaptées à leur environnement. Se posent alors deux questions : quelle doit être la nature des représentations utilisées et par quels mécanismes peuvent-elles être apprises ? Nous proposons pour cela l'utilisation de l'hypothèse des sous-variétés afin de développer des architectures permettant de faire émerger une représentation symbolique de flux sensorimoteurs bruts. Nous montrons que le paradigme de l'apprentissage profond fournit des mécanismes appropriés à l'apprentissage autonome de telles représentations. Nous démontrons que l'exploitation de la nature multimodale des flux sensorimoteurs permet d'en obtenir une représentation symbolique pertinente. Dans un second temps, nous étudions le problème de l'évolution temporelle des stimuli. Nous discutons les défauts de la plupart des approches aujourd'hui utilisées et nous esquissons une approche à partir de laquelle nous approfondissons deux sous-problèmes. Dans une troisième partie, nous proposons des pistes de recherche pour permettre le passage des expériences de laboratoire à des environnements naturels. Nous explorons plus particulièrement la problématique de la curiosité artificielle dans des réseaux de neurones non supervisés.},
	urldate = {2016-10-10TZ},
	publisher = {Paris 6},
	author = {Droniou, Alain},
	month = mar,
	year = {2015},
	keywords = {deep learning, developmental robotics, symbol grounding problem}
}

@article{mnih_human-level_2015,
	title = {Human-level control through deep reinforcement learning},
	volume = {518},
	copyright = {© 2015 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {0028-0836},
	url = {http://www.nature.com/nature/journal/v518/n7540/full/nature14236.html},
	doi = {10.1038/nature14236},
	abstract = {The theory of reinforcement learning provides a normative account, deeply rooted in psychological and neuroscientific perspectives on animal behaviour, of how agents may optimize their control of an environment. To use reinforcement learning successfully in situations approaching real-world complexity, however, agents are confronted with a difficult task: they must derive efficient representations of the environment from high-dimensional sensory inputs, and use these to generalize past experience to new situations. Remarkably, humans and other animals seem to solve this problem through a harmonious combination of reinforcement learning and hierarchical sensory processing systems, the former evidenced by a wealth of neural data revealing notable parallels between the phasic signals emitted by dopaminergic neurons and temporal difference reinforcement learning algorithms. While reinforcement learning agents have achieved some successes in a variety of domains, their applicability has previously been limited to domains in which useful features can be handcrafted, or to domains with fully observed, low-dimensional state spaces. Here we use recent advances in training deep neural networks to develop a novel artificial agent, termed a deep Q-network, that can learn successful policies directly from high-dimensional sensory inputs using end-to-end reinforcement learning. We tested this agent on the challenging domain of classic Atari 2600 games. We demonstrate that the deep Q-network agent, receiving only the pixels and the game score as inputs, was able to surpass the performance of all previous algorithms and achieve a level comparable to that of a professional human games tester across a set of 49 games, using the same algorithm, network architecture and hyperparameters. This work bridges the divide between high-dimensional sensory inputs and actions, resulting in the first artificial agent that is capable of learning to excel at a diverse array of challenging tasks.},
	language = {en},
	number = {7540},
	urldate = {2016-10-10TZ},
	journal = {Nature},
	author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
	month = feb,
	year = {2015},
	keywords = {deep reinforcement learning},
	pages = {529--533}
}

@misc{noauthor_developmental_nodate,
	title = {Developmental {Robotics}},
	url = {https://mitpress.mit.edu/books/developmental-robotics},
	abstract = {A comprehensive overview of an interdisciplinary approach to robotics that takes direct inspiration from the developmental and learning phenomena observed in children’s cognitive development.},
	urldate = {2016-10-10TZ},
	journal = {MIT Press},
	keywords = {developmental robotics}
}

@article{mnih_asynchronous_2016,
	title = {Asynchronous {Methods} for {Deep} {Reinforcement} {Learning}},
	url = {http://arxiv.org/abs/1602.01783},
	abstract = {We propose a conceptually simple and lightweight framework for deep reinforcement learning that uses asynchronous gradient descent for optimization of deep neural network controllers. We present asynchronous variants of four standard reinforcement learning algorithms and show that parallel actor-learners have a stabilizing effect on training allowing all four methods to successfully train neural network controllers. The best performing method, an asynchronous variant of actor-critic, surpasses the current state-of-the-art on the Atari domain while training for half the time on a single multi-core CPU instead of a GPU. Furthermore, we show that asynchronous actor-critic succeeds on a wide variety of continuous motor control problems as well as on a new task of navigating random 3D mazes using a visual input.},
	urldate = {2016-10-10TZ},
	journal = {arXiv:1602.01783 [cs]},
	author = {Mnih, Volodymyr and Badia, Adrià Puigdomènech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy P. and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
	month = feb,
	year = {2016},
	note = {arXiv: 1602.01783},
	keywords = {asynchronous learning, deep learning, deep reinforcement learning, reinforcement learning}
}

@article{sigaud_towards_2016,
	title = {Towards {Deep} {Developmental} {Learning}},
	volume = {8},
	issn = {2379-8920},
	doi = {10.1109/TAMD.2015.2496248},
	abstract = {Deep learning techniques are having an undeniable impact on general pattern recognition issues. In this paper, from a developmental robotics perspective, we scrutinize deep learning techniques under the light of their capability to construct a hierarchy of meaningful multimodal representations from the raw sensors of robots. These investigations reveal the differences between the methodological constraints of pattern recognition and those of developmental robotics. In particular, we outline the necessity to rely on unsupervised rather than supervised learning methods and we highlight the need for progress towards the implementation of hierarchical predictive processing capabilities. Based on these new tools, we outline the emergence of a new domain that we call deep developmental learning.},
	number = {2},
	journal = {IEEE Transactions on Cognitive and Developmental Systems},
	author = {Sigaud, O. and Droniou, A.},
	month = jun,
	year = {2016},
	keywords = {deep developmental learning},
	pages = {99--114}
}

@article{piekniewski_unsupervised_2016,
	title = {Unsupervised {Learning} from {Continuous} {Video} in a {Scalable} {Predictive} {Recurrent} {Network}},
	url = {http://arxiv.org/abs/1607.06854},
	abstract = {Understanding visual reality involves acquiring common-sense knowledge about countless regularities in the visual world, e.g., how illumination alters the appearance of objects in a scene, and how motion changes their apparent spatial relationship. These regularities are hard to label for training supervised machine learning algorithms; consequently, algorithms need to learn these regularities from the real world in an unsupervised way. We present a novel network meta-architecture that can learn world dynamics from raw, continuous video. The components of this network can be implemented using any algorithm that possesses three key capabilities: prediction of a signal over time, reduction of signal dimensionality (compression), and the ability to use supplementary contextual information to inform the prediction. The presented architecture is highly-parallelized and scalable, and is implemented using localized connectivity, processing, and learning. We demonstrate an implementation of this architecture where the components are built from multi-layer perceptrons. We apply the implementation to create a system capable of stable and robust visual tracking of objects as seen by a moving camera. Results show performance on par with or exceeding state-of-the-art tracking algorithms. The tracker can be trained in either fully supervised or unsupervised-then-briefly-supervised regimes. Success of the briefly-supervised regime suggests that the unsupervised portion of the model extracts useful information about visual reality. The results suggest a new class of AI algorithms that uniquely combine prediction and scalability in a way that makes them suitable for learning from and --- and eventually acting within --- the real world.},
	urldate = {2016-10-10TZ},
	journal = {arXiv:1607.06854 [cs]},
	author = {Piekniewski, Filip and Laurent, Patryk and Petre, Csaba and Richert, Micah and Fisher, Dimitry and Hylton, Todd},
	month = jul,
	year = {2016},
	note = {arXiv: 1607.06854},
	keywords = {\_tablet}
}

@article{vollmer_robots_2014,
	title = {Robots {Show} {Us} {How} to {Teach} {Them}: {Feedback} from {Robots} {Shapes} {Tutoring} {Behavior} during {Action} {Learning}},
	volume = {9},
	issn = {1932-6203},
	shorttitle = {Robots {Show} {Us} {How} to {Teach} {Them}},
	url = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0091349},
	doi = {10.1371/journal.pone.0091349},
	abstract = {Robot learning by imitation requires the detection of a tutor's action demonstration and its relevant parts. Current approaches implicitly assume a unidirectional transfer of knowledge from tutor to learner. The presented work challenges this predominant assumption based on an extensive user study with an autonomously interacting robot. We show that by providing feedback, a robot learner influences the human tutor's movement demonstrations in the process of action learning. We argue that the robot's feedback strongly shapes how tutors signal what is relevant to an action and thus advocate a paradigm shift in robot action learning research toward truly interactive systems learning in and benefiting from interaction.},
	number = {3},
	urldate = {2016-10-10TZ},
	journal = {PLOS ONE},
	author = {Vollmer, Anna-Lisa and Mühlig, Manuel and Steil, Jochen J. and Pitsch, Karola and Fritsch, Jannik and Rohlfing, Katharina J. and Wrede, Britta},
	month = mar,
	year = {2014},
	pages = {e91349}
}

@article{salam_fully_2016,
	title = {Fully {Automatic} {Analysis} of {Engagement} and {Its} {Relationship} to {Personality} in {Human}-{Robot} {Interactions}},
	volume = {PP},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2016.2614525},
	abstract = {Engagement is crucial to designing intelligent systems that can adapt to the characteristics of their users. This paper focuses on automatic analysis and classification of engagement based on humans’ and robot’s personality profiles in a triadic human-human-robot interaction setting. More explicitly, we present a study that involves two participants interacting with a humanoid robot, and investigate how participants’ personalities can be used together with the robot’s personality to predict the engagement state of each participant. The fully automatic system is firstly trained to predict the Big Five personality traits of each participant by extracting individual and interpersonal features from their nonverbal behavioural cues. Secondly, the output of the personality prediction system is used as an input to the engagement classification system. Thirdly, we focus on the concept of “group engagement”, which we define as the collective engagement of the participants with the robot, and analyse the impact of similar and dissimilar personalities on the engagement classification. Our experimental results show that (i) using the automatically predicted personality labels for engagement classification yields an F-measure on par with using the manually annotated personality labels, demonstrating the effectiveness of the automatic personality prediction module proposed; (ii) using the individual and interpersonal features without utilising personality information is not sufficient for engagement classification, instead incorporating the participants’ and robot’s personalities with individual/interpersonal features increases engagement classification performance; and (iii) the best classification performance is achieved when the participants and the robot are extroverted, while the worst results are obt- ined when all are introverted.},
	number = {99},
	journal = {IEEE Access},
	author = {Salam, H. and Celiktutan, O. and Hupont, I. and Gunes, H. and Chetouani, M.},
	year = {2016},
	keywords = {human robot interaction, personality, social engagement},
	pages = {1--1}
}